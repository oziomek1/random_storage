{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet50_functional_cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "NhJbILGU3yfv",
        "outputId": "f06294c7-5fba-4606-9c01-624d7aa7700b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation, add, Dense, Dropout, Flatten, Input, GlobalAveragePooling2D, concatenate\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.utils.vis_utils import model_to_dot, plot_model\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qk_-mgR52-NA",
        "outputId": "7ba065b4-5891-4b35-d9f2-2a1ee0c57efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 7084082618335300217, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 5956834645192690220\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 17163276474129383766\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 11281553818\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 10185667557451325392\n",
              " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "C5j4ewbL2ph-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "049dd7ca-8072-4ef4-82b8-1742ea47d953"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 22s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GSjprgpA2-5o",
        "outputId": "c36bb1a6-78f4-42e7-af13-f252565f5b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 1), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "03yIVAd53ZcE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xydCaXd_3dtD",
        "outputId": "f060a93e-bc67-4dc9-81a1-5e8dbbb2ce6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "mean, std"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4733630004850874, 0.25156892506322026)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "Xjtzl9NZwAfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# x_train = (x_train-mean)/(std+1e-7)\n",
        "# x_test = (x_test-mean)/(std+1e-7)\n",
        "x_train -= mean\n",
        "x_test -= mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZsRPjIF-3gjE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NUsBxbWmFJ9x",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def residual_block(input_layer, channels_in, channels_out, stride=(1,1), proj_shortcut=False, bottleneck=False):\n",
        "#     shortcut = input_layer\n",
        "\n",
        "#     first_kernel=(3,3)\n",
        "#     first_strides=stride\n",
        "\n",
        "#     fixed_strides=(1,1)\n",
        "#     fixed_kernel=(1,1)\n",
        "\n",
        "#     if bottleneck:\n",
        "#         first_kernel=(1,1)\n",
        "#         first_strides=(1,1)\n",
        "\n",
        "#     y = Conv2D(channels_in, kernel_size=first_kernel, strides=first_strides, padding='same')(input_layer)\n",
        "#     y = norm_and_activation(y)\n",
        "\n",
        "#     if bottleneck:\n",
        "#         y = grouped_convolution(y, channels_in, stride)\n",
        "#         y = norm_and_activation(y)\n",
        "\n",
        "#     y = Conv2D(channels_out, kernel_size=first_kernel, strides=fixed_strides, padding='same')(y)\n",
        "#     y = norm(y)\n",
        "\n",
        "#     if proj_shortcut or stride != fixed_strides:\n",
        "#         shortcut = Conv2D(channels_out, kernel_size=fixed_kernel, strides=stride, padding='same')(shortcut)\n",
        "#         shortcut = norm(shortcut)\n",
        "\n",
        "#     print(proj_shortcut, stride, shortcut.shape, y.shape)\n",
        "#     y = add([shortcut, y])\n",
        "#     y = norm_and_activation(y, False)\n",
        "\n",
        "#     return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MeUA2Dtw6IaZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def dynamic_lr(epoch):\n",
        "    lr = 0.5e-3\n",
        "    if epoch > 25:\n",
        "      lr *= 1e-1\n",
        "    elif epoch > 50:\n",
        "      lr *= 1e-2\n",
        "    elif epoch > 75:\n",
        "      lr *= 1e-3\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "01M0-2zhD-Go",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def norm_and_activation(input_layer, norm=True, activate=True):\n",
        "    if norm:\n",
        "        input_layer = BatchNormalization()(input_layer)\n",
        "    if activate:\n",
        "        input_layer = Activation('relu')(input_layer)\n",
        "    return input_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZ-NtbTiq_Eh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def residual_block(input_layer, channels_in, channels_out, stride=(1,1), proj_short=False, bottleneck=False):\n",
        "    short_path = input_layer\n",
        "    y = input_layer\n",
        "    y = norm_and_activation(y, False, True)\n",
        "    y = Conv2D(channels_in, kernel_size=(1,1), strides=stride, padding='same')(y)\n",
        "    print('sub_block_1, [ 1x1,', channels_in, ']')\n",
        "    y = norm_and_activation(y)\n",
        "    y = Conv2D(channels_in, kernel_size=(3,3), strides=(1,1), padding='same')(y)\n",
        "    print('sub_block_2, [ 3x3,', channels_in, ']')\n",
        "    y = norm_and_activation(y)\n",
        "    y = Conv2D(channels_out, kernel_size=(1,1), strides=(1,1), padding='same')(y)\n",
        "    print('sub_block_3, [ 1x1,', channels_out, ']')\n",
        "    if proj_short or stride != (1,1):\n",
        "        short_path = Conv2D(channels_out, kernel_size=(1,1), strides=stride, padding='same')(short_path)\n",
        "        short_path = norm_and_activation(short_path, True, False)\n",
        "    y = add([short_path, y])\n",
        "    y = norm_and_activation(y, False, True)\n",
        "    print('First layer', proj_short, ', Stride size', stride, ', Shape', y.shape)\n",
        "\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UvQhW75l3k1O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model(conv_size, lr, input_shape, bottleneck=False):\n",
        "    conv_size_double = conv_size * 4\n",
        "    initial = Input(shape=input_shape)\n",
        "\n",
        "    conv_11 = Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', activation='relu')(initial)\n",
        "    conv_11 = norm_and_activation(conv_11)\n",
        "\n",
        "    pool_1 = MaxPooling2D((2, 2), padding='valid')(conv_11)\n",
        "\n",
        "    block_11 = residual_block(pool_1, channels_in=conv_size, channels_out=conv_size_double, proj_short=True, bottleneck=bottleneck)\n",
        "    block_12 = residual_block(block_11, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_13 = residual_block(block_12, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "\n",
        "    conv_size *= 2\n",
        "    conv_size_double *= 2\n",
        "    \n",
        "    block_21 = residual_block(block_13, channels_in=conv_size, channels_out=conv_size_double, stride=(2,2), bottleneck=bottleneck)\n",
        "    block_22 = residual_block(block_21, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_23 = residual_block(block_22, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_24 = residual_block(block_23, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "\n",
        "    conv_size *= 2\n",
        "    conv_size_double *= 2\n",
        "    \n",
        "    block_31 = residual_block(block_24, channels_in=conv_size, channels_out=conv_size_double, stride=(2,2), bottleneck=bottleneck)\n",
        "    block_32 = residual_block(block_31, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_33 = residual_block(block_32, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_34 = residual_block(block_33, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_35 = residual_block(block_34, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_36 = residual_block(block_35, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "\n",
        "    conv_size *= 2\n",
        "    conv_size_double *= 2\n",
        "    \n",
        "    block_41 = residual_block(block_36, channels_in=conv_size, channels_out=conv_size_double, stride=(2,2), bottleneck=bottleneck)\n",
        "    block_42 = residual_block(block_41, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "    block_43 = residual_block(block_42, channels_in=conv_size, channels_out=conv_size_double, bottleneck=bottleneck)\n",
        "  \n",
        "    pool_21 = GlobalAveragePooling2D()(block_43)\n",
        "\n",
        "    hidden_1 = Dense(1000, kernel_initializer='random_uniform', activation='relu')(pool_21)\n",
        "    predictions = Dense(10, activation='softmax')(hidden_1)\n",
        "    model = Model(inputs=initial, outputs=predictions)\n",
        "    adam = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-5, amsgrad=True)\n",
        "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dARMR0YJ5O2R",
        "outputId": "052876b6-ea92-4de8-ae72-0c4bc168947e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "model = model(64, dynamic_lr(0), (32,32,3), True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Learning rate:  0.0005\n",
            "sub_block_1, [ 1x1, 64 ]\n",
            "sub_block_2, [ 3x3, 64 ]\n",
            "sub_block_3, [ 1x1, 256 ]\n",
            "First layer True , Stride size (1, 1) , Shape (?, 8, 8, 256)\n",
            "sub_block_1, [ 1x1, 64 ]\n",
            "sub_block_2, [ 3x3, 64 ]\n",
            "sub_block_3, [ 1x1, 256 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 8, 8, 256)\n",
            "sub_block_1, [ 1x1, 64 ]\n",
            "sub_block_2, [ 3x3, 64 ]\n",
            "sub_block_3, [ 1x1, 256 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 8, 8, 256)\n",
            "sub_block_1, [ 1x1, 128 ]\n",
            "sub_block_2, [ 3x3, 128 ]\n",
            "sub_block_3, [ 1x1, 512 ]\n",
            "First layer False , Stride size (2, 2) , Shape (?, 4, 4, 512)\n",
            "sub_block_1, [ 1x1, 128 ]\n",
            "sub_block_2, [ 3x3, 128 ]\n",
            "sub_block_3, [ 1x1, 512 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 4, 4, 512)\n",
            "sub_block_1, [ 1x1, 128 ]\n",
            "sub_block_2, [ 3x3, 128 ]\n",
            "sub_block_3, [ 1x1, 512 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 4, 4, 512)\n",
            "sub_block_1, [ 1x1, 128 ]\n",
            "sub_block_2, [ 3x3, 128 ]\n",
            "sub_block_3, [ 1x1, 512 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 4, 4, 512)\n",
            "sub_block_1, [ 1x1, 256 ]\n",
            "sub_block_2, [ 3x3, 256 ]\n",
            "sub_block_3, [ 1x1, 1024 ]\n",
            "First layer False , Stride size (2, 2) , Shape (?, 2, 2, 1024)\n",
            "sub_block_1, [ 1x1, 256 ]\n",
            "sub_block_2, [ 3x3, 256 ]\n",
            "sub_block_3, [ 1x1, 1024 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 2, 2, 1024)\n",
            "sub_block_1, [ 1x1, 256 ]\n",
            "sub_block_2, [ 3x3, 256 ]\n",
            "sub_block_3, [ 1x1, 1024 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 2, 2, 1024)\n",
            "sub_block_1, [ 1x1, 256 ]\n",
            "sub_block_2, [ 3x3, 256 ]\n",
            "sub_block_3, [ 1x1, 1024 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 2, 2, 1024)\n",
            "sub_block_1, [ 1x1, 256 ]\n",
            "sub_block_2, [ 3x3, 256 ]\n",
            "sub_block_3, [ 1x1, 1024 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 2, 2, 1024)\n",
            "sub_block_1, [ 1x1, 256 ]\n",
            "sub_block_2, [ 3x3, 256 ]\n",
            "sub_block_3, [ 1x1, 1024 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 2, 2, 1024)\n",
            "sub_block_1, [ 1x1, 512 ]\n",
            "sub_block_2, [ 3x3, 512 ]\n",
            "sub_block_3, [ 1x1, 2048 ]\n",
            "First layer False , Stride size (2, 2) , Shape (?, 1, 1, 2048)\n",
            "sub_block_1, [ 1x1, 512 ]\n",
            "sub_block_2, [ 3x3, 512 ]\n",
            "sub_block_3, [ 1x1, 2048 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 1, 1, 2048)\n",
            "sub_block_1, [ 1x1, 512 ]\n",
            "sub_block_2, [ 3x3, 512 ]\n",
            "sub_block_3, [ 1x1, 2048 ]\n",
            "First layer False , Stride size (1, 1) , Shape (?, 1, 1, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tMBXnmrb55Y6",
        "outputId": "ef102cf9-1320-49bb-df3b-e52626f585de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6409
        }
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 16, 16, 64)   1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 16, 16, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 16, 16, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 8, 8, 64)     0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 8, 8, 64)     4160        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 8, 8, 64)     256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 8, 8, 64)     0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 8, 8, 64)     36928       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 8, 8, 64)     256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 8, 8, 256)    16640       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 256)    1024        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 256)    16640       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 8, 8, 256)    0           batch_normalization_4[0][0]      \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 256)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 8, 8, 256)    0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 8, 8, 64)     16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 8, 8, 64)     36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 8, 8, 64)     256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 8, 8, 64)     0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 8, 8, 256)    16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 8, 8, 256)    0           activation_5[0][0]               \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 8, 8, 256)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 8, 8, 256)    0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 8, 8, 64)     16448       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 8, 8, 64)     256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 8, 8, 64)     0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 8, 8, 64)     36928       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 8, 8, 64)     256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 8, 8, 64)     0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 8, 8, 256)    16640       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 8, 8, 256)    0           activation_9[0][0]               \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 256)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 256)    0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 4, 4, 128)    32896       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 4, 4, 128)    512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 4, 4, 128)    0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 4, 4, 128)    147584      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 4, 4, 128)    512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 4, 4, 512)    131584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 4, 4, 128)    0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 4, 4, 512)    2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 4, 4, 512)    66048       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 4, 4, 512)    0           batch_normalization_11[0][0]     \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 4, 4, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 4, 512)    0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 4, 4, 128)    65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 4, 4, 128)    512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 4, 128)    0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 4, 4, 128)    147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 4, 4, 128)    512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 4, 4, 128)    0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 4, 512)    66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 4, 4, 512)    0           activation_17[0][0]              \n",
            "                                                                 conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 4, 4, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 4, 4, 512)    0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 4, 128)    65664       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 4, 4, 128)    512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 4, 4, 128)    0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 4, 4, 128)    147584      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 4, 4, 128)    512         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 4, 4, 128)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 4, 4, 512)    66048       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 4, 4, 512)    0           activation_21[0][0]              \n",
            "                                                                 conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 4, 4, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 4, 4, 512)    0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 4, 4, 128)    65664       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 4, 4, 128)    512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 4, 4, 128)    0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 4, 4, 128)    147584      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 4, 4, 128)    512         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 4, 4, 128)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 4, 4, 512)    66048       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 4, 4, 512)    0           activation_25[0][0]              \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 4, 4, 512)    0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 4, 4, 512)    0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 2, 2, 256)    131328      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 2, 2, 256)    1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 2, 2, 256)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 2, 2, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 2, 2, 256)    1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 2, 2, 1024)   525312      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 2, 2, 256)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 2, 2, 1024)   4096        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 2, 2, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 2, 1024)   0           batch_normalization_20[0][0]     \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 2, 2, 1024)   0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 2, 2, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 2, 2, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 2, 2, 256)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 2, 2, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 2, 2, 256)    1024        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 2, 2, 256)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 2, 2, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 1024)   0           activation_33[0][0]              \n",
            "                                                                 conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 2, 2, 1024)   0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 2, 2, 256)    262400      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 2, 2, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 2, 2, 256)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 2, 2, 256)    590080      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 2, 2, 256)    1024        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 2, 2, 256)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 2, 2, 1024)   263168      activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 1024)   0           activation_37[0][0]              \n",
            "                                                                 conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 2, 2, 1024)   0           activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 2, 2, 256)    262400      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 2, 2, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 2, 2, 256)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 2, 2, 256)    590080      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 2, 2, 256)    1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 2, 2, 256)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 2, 2, 1024)   263168      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 2, 2, 1024)   0           activation_41[0][0]              \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 2, 2, 1024)   0           activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 2, 2, 256)    262400      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 2, 2, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 2, 2, 256)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 2, 2, 256)    590080      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 2, 2, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 2, 2, 256)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 2, 2, 1024)   263168      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 2, 2, 1024)   0           activation_45[0][0]              \n",
            "                                                                 conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 2, 2, 1024)   0           activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 2, 2, 256)    262400      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 2, 2, 256)    1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 2, 2, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 2, 2, 256)    590080      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 2, 2, 256)    1024        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 2, 2, 256)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 2, 2, 1024)   263168      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 2, 2, 1024)   0           activation_49[0][0]              \n",
            "                                                                 conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 2, 2, 1024)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 2, 2, 1024)   0           activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 1, 1, 512)    524800      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 1, 1, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 1, 1, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 1, 1, 512)    2359808     activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 1, 1, 512)    2048        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 1, 1, 2048)   2099200     activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 1, 1, 512)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 1, 1, 2048)   8192        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 1, 1, 2048)   0           batch_normalization_33[0][0]     \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 1, 1, 2048)   0           activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 1, 1, 512)    1049088     activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 1, 1, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 1, 1, 512)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 1, 1, 512)    2359808     activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 1, 1, 512)    2048        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 1, 1, 512)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 1, 1, 2048)   0           activation_57[0][0]              \n",
            "                                                                 conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 1, 1, 2048)   0           activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 1, 1, 512)    1049088     activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 1, 1, 512)    2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 1, 1, 512)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 1, 1, 512)    2359808     activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 1, 1, 512)    2048        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 1, 1, 512)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 1, 1, 2048)   1050624     activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 1, 1, 2048)   0           activation_61[0][0]              \n",
            "                                                                 conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 1, 1, 2048)   0           add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1000)         2049000     global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           10010       dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 25,578,626\n",
            "Trainable params: 25,555,714\n",
            "Non-trainable params: 22,912\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7f7AMTIOq_Eu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='resnet50_cifar10.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "niJKsNAMq_Ex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "svg_plot = model_to_dot(model).create(prog='dot', format='svg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "On4xYNhnq_E0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('svg_plot.svg', 'wb') as file:\n",
        "    file.write(svg_plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3Zn76z5Hf83N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "batch_size = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQzr2gwH8pvZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "checkpoint = ModelCheckpoint('resnet50_cifar10_weights_{epoch:04d}_{acc:.4f}.h5', save_weights_only=True, period=10, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xngLJSVf566h",
        "outputId": "0fc31c4e-0f82-4940-9550-e1e011483a33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3774
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, shuffle=True, epochs=epochs, verbose=1, validation_split=0.2, callbacks=[checkpoint])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 62s 2ms/step - loss: 1.8340 - acc: 0.3779 - val_loss: 1.6373 - val_acc: 0.4087\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 39s 969us/step - loss: 1.2166 - acc: 0.5638 - val_loss: 1.4807 - val_acc: 0.4882\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.9131 - acc: 0.6760 - val_loss: 1.4816 - val_acc: 0.4903\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.6794 - acc: 0.7614 - val_loss: 1.4012 - val_acc: 0.5647\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.4916 - acc: 0.8279 - val_loss: 1.6002 - val_acc: 0.5460\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.3784 - acc: 0.8678 - val_loss: 1.6103 - val_acc: 0.5584\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.2935 - acc: 0.8977 - val_loss: 1.5902 - val_acc: 0.5836\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.2292 - acc: 0.9184 - val_loss: 1.7941 - val_acc: 0.5698\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.1815 - acc: 0.9357 - val_loss: 1.8946 - val_acc: 0.5850\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.1741 - acc: 0.9382 - val_loss: 1.9239 - val_acc: 0.5735\n",
            "\n",
            "Epoch 00010: saving model to resnet50_cifar10_weights_0010_0.9382.h5\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 39s 986us/step - loss: 0.1150 - acc: 0.9604 - val_loss: 1.9435 - val_acc: 0.5895\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.1033 - acc: 0.9642 - val_loss: 2.2360 - val_acc: 0.5704\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.1244 - acc: 0.9557 - val_loss: 1.9835 - val_acc: 0.6039\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0967 - acc: 0.9669 - val_loss: 2.0976 - val_acc: 0.6000\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0707 - acc: 0.9757 - val_loss: 2.1566 - val_acc: 0.5985\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0866 - acc: 0.9699 - val_loss: 2.1697 - val_acc: 0.5926\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0663 - acc: 0.9769 - val_loss: 2.1695 - val_acc: 0.6062\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0863 - acc: 0.9704 - val_loss: 2.1354 - val_acc: 0.5952\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0687 - acc: 0.9762 - val_loss: 2.1578 - val_acc: 0.6127\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 39s 983us/step - loss: 0.0344 - acc: 0.9883 - val_loss: 2.2740 - val_acc: 0.6179\n",
            "\n",
            "Epoch 00020: saving model to resnet50_cifar10_weights_0020_0.9883.h5\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0455 - acc: 0.9849 - val_loss: 2.1785 - val_acc: 0.6191\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0381 - acc: 0.9869 - val_loss: 2.3859 - val_acc: 0.6093\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0449 - acc: 0.9848 - val_loss: 2.3070 - val_acc: 0.6145\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0716 - acc: 0.9761 - val_loss: 2.1095 - val_acc: 0.6249\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0471 - acc: 0.9839 - val_loss: 2.1254 - val_acc: 0.6277\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0578 - acc: 0.9801 - val_loss: 2.1747 - val_acc: 0.6157\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0422 - acc: 0.9862 - val_loss: 2.0913 - val_acc: 0.6233\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0412 - acc: 0.9868 - val_loss: 2.2837 - val_acc: 0.6190\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0298 - acc: 0.9896 - val_loss: 2.1810 - val_acc: 0.6358\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0273 - acc: 0.9910 - val_loss: 2.2511 - val_acc: 0.6344\n",
            "\n",
            "Epoch 00030: saving model to resnet50_cifar10_weights_0030_0.9910.h5\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0295 - acc: 0.9899 - val_loss: 2.2765 - val_acc: 0.6266\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0189 - acc: 0.9933 - val_loss: 2.3403 - val_acc: 0.6297\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0564 - acc: 0.9808 - val_loss: 2.1934 - val_acc: 0.6227\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0313 - acc: 0.9889 - val_loss: 2.2933 - val_acc: 0.6229\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 39s 983us/step - loss: 0.0254 - acc: 0.9919 - val_loss: 2.2642 - val_acc: 0.6355\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0307 - acc: 0.9899 - val_loss: 2.3042 - val_acc: 0.6236\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0295 - acc: 0.9900 - val_loss: 2.3418 - val_acc: 0.6219\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0133 - acc: 0.9956 - val_loss: 2.2647 - val_acc: 0.6428\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0056 - acc: 0.9986 - val_loss: 2.3663 - val_acc: 0.6406\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0178 - acc: 0.9942 - val_loss: 2.5109 - val_acc: 0.6263\n",
            "\n",
            "Epoch 00040: saving model to resnet50_cifar10_weights_0040_0.9942.h5\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0187 - acc: 0.9940 - val_loss: 2.4492 - val_acc: 0.6255\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0119 - acc: 0.9959 - val_loss: 2.4035 - val_acc: 0.6396\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0313 - acc: 0.9892 - val_loss: 2.3422 - val_acc: 0.6311\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0263 - acc: 0.9909 - val_loss: 2.3036 - val_acc: 0.6323\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0183 - acc: 0.9937 - val_loss: 2.2662 - val_acc: 0.6438\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0177 - acc: 0.9943 - val_loss: 2.2898 - val_acc: 0.6401\n",
            "Epoch 47/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0232 - acc: 0.9913 - val_loss: 2.2999 - val_acc: 0.6331\n",
            "Epoch 48/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0156 - acc: 0.9946 - val_loss: 2.3903 - val_acc: 0.6326\n",
            "Epoch 49/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0186 - acc: 0.9937 - val_loss: 2.4378 - val_acc: 0.6278\n",
            "Epoch 50/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0113 - acc: 0.9963 - val_loss: 2.3821 - val_acc: 0.6418\n",
            "\n",
            "Epoch 00050: saving model to resnet50_cifar10_weights_0050_0.9963.h5\n",
            "Epoch 51/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0100 - acc: 0.9966 - val_loss: 2.4005 - val_acc: 0.6431\n",
            "Epoch 52/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0080 - acc: 0.9971 - val_loss: 2.4912 - val_acc: 0.6425\n",
            "Epoch 53/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0033 - acc: 0.9990 - val_loss: 2.4637 - val_acc: 0.6541\n",
            "Epoch 54/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0238 - acc: 0.9919 - val_loss: 2.4885 - val_acc: 0.6267\n",
            "Epoch 55/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0113 - acc: 0.9964 - val_loss: 2.5041 - val_acc: 0.6442\n",
            "Epoch 56/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0068 - acc: 0.9976 - val_loss: 2.5854 - val_acc: 0.6354\n",
            "Epoch 57/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0036 - acc: 0.9989 - val_loss: 2.5003 - val_acc: 0.6475\n",
            "Epoch 58/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0027 - acc: 0.9992 - val_loss: 2.5396 - val_acc: 0.6435\n",
            "Epoch 59/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0235 - acc: 0.9924 - val_loss: 2.4407 - val_acc: 0.6364\n",
            "Epoch 60/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0160 - acc: 0.9949 - val_loss: 2.4468 - val_acc: 0.6404\n",
            "\n",
            "Epoch 00060: saving model to resnet50_cifar10_weights_0060_0.9949.h5\n",
            "Epoch 61/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0074 - acc: 0.9977 - val_loss: 2.5151 - val_acc: 0.6435\n",
            "Epoch 62/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 2.4779 - val_acc: 0.6474\n",
            "Epoch 63/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0034 - acc: 0.9990 - val_loss: 2.6094 - val_acc: 0.6461\n",
            "Epoch 64/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0206 - acc: 0.9938 - val_loss: 2.5427 - val_acc: 0.6400\n",
            "Epoch 65/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0084 - acc: 0.9970 - val_loss: 2.5166 - val_acc: 0.6415\n",
            "Epoch 66/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0324 - acc: 0.9895 - val_loss: 2.4359 - val_acc: 0.6394\n",
            "Epoch 67/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 2.3401 - val_acc: 0.6447\n",
            "Epoch 68/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0068 - acc: 0.9980 - val_loss: 2.3378 - val_acc: 0.6477\n",
            "Epoch 69/100\n",
            "40000/40000 [==============================] - 39s 983us/step - loss: 0.0109 - acc: 0.9968 - val_loss: 2.3975 - val_acc: 0.6520\n",
            "Epoch 70/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0077 - acc: 0.9975 - val_loss: 2.4670 - val_acc: 0.6532\n",
            "\n",
            "Epoch 00070: saving model to resnet50_cifar10_weights_0070_0.9975.h5\n",
            "Epoch 71/100\n",
            "40000/40000 [==============================] - 39s 983us/step - loss: 0.0151 - acc: 0.9950 - val_loss: 2.4570 - val_acc: 0.6476\n",
            "Epoch 72/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 0.0170 - acc: 0.9947 - val_loss: 2.4206 - val_acc: 0.6451\n",
            "Epoch 73/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0056 - acc: 0.9982 - val_loss: 2.3751 - val_acc: 0.6563\n",
            "Epoch 74/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0065 - acc: 0.9978 - val_loss: 2.4907 - val_acc: 0.6502\n",
            "Epoch 75/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0026 - acc: 0.9991 - val_loss: 2.5383 - val_acc: 0.6574\n",
            "Epoch 76/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0021 - acc: 0.9994 - val_loss: 2.5200 - val_acc: 0.6586\n",
            "Epoch 77/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 2.5717 - val_acc: 0.6557\n",
            "Epoch 78/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 6.0805e-04 - acc: 0.9999 - val_loss: 2.5620 - val_acc: 0.6624\n",
            "Epoch 79/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 6.5761e-04 - acc: 0.9998 - val_loss: 2.6090 - val_acc: 0.6548\n",
            "Epoch 80/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 3.7526e-04 - acc: 0.9999 - val_loss: 2.5953 - val_acc: 0.6570\n",
            "\n",
            "Epoch 00080: saving model to resnet50_cifar10_weights_0080_0.9999.h5\n",
            "Epoch 81/100\n",
            "40000/40000 [==============================] - 39s 981us/step - loss: 1.0568e-04 - acc: 1.0000 - val_loss: 2.6009 - val_acc: 0.6609\n",
            "Epoch 82/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 4.5109e-04 - acc: 0.9999 - val_loss: 2.7112 - val_acc: 0.6537\n",
            "Epoch 83/100\n",
            "40000/40000 [==============================] - 39s 982us/step - loss: 0.0838 - acc: 0.9748 - val_loss: 2.2432 - val_acc: 0.6384\n",
            "Epoch 84/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0140 - acc: 0.9948 - val_loss: 2.1753 - val_acc: 0.6525\n",
            "Epoch 85/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0110 - acc: 0.9963 - val_loss: 2.1924 - val_acc: 0.6553\n",
            "Epoch 86/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0180 - acc: 0.9940 - val_loss: 2.2920 - val_acc: 0.6457\n",
            "Epoch 87/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 2.3184 - val_acc: 0.6520\n",
            "Epoch 88/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0033 - acc: 0.9989 - val_loss: 2.3391 - val_acc: 0.6563\n",
            "Epoch 89/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 2.4200 - val_acc: 0.6583\n",
            "Epoch 90/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0024 - acc: 0.9992 - val_loss: 2.4654 - val_acc: 0.6582\n",
            "\n",
            "Epoch 00090: saving model to resnet50_cifar10_weights_0090_0.9992.h5\n",
            "Epoch 91/100\n",
            "40000/40000 [==============================] - 39s 980us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 2.5578 - val_acc: 0.6575\n",
            "Epoch 92/100\n",
            "40000/40000 [==============================] - 39s 976us/step - loss: 8.6101e-04 - acc: 0.9998 - val_loss: 2.4963 - val_acc: 0.6634\n",
            "Epoch 93/100\n",
            "40000/40000 [==============================] - 39s 979us/step - loss: 0.0094 - acc: 0.9977 - val_loss: 2.5125 - val_acc: 0.6517\n",
            "Epoch 94/100\n",
            "40000/40000 [==============================] - 39s 977us/step - loss: 0.0031 - acc: 0.9990 - val_loss: 2.4971 - val_acc: 0.6561\n",
            "Epoch 95/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 2.5439 - val_acc: 0.6547\n",
            "Epoch 96/100\n",
            "40000/40000 [==============================] - 39s 976us/step - loss: 0.0023 - acc: 0.9993 - val_loss: 2.6340 - val_acc: 0.6518\n",
            "Epoch 97/100\n",
            "40000/40000 [==============================] - 39s 977us/step - loss: 0.0187 - acc: 0.9947 - val_loss: 2.5304 - val_acc: 0.6460\n",
            "Epoch 98/100\n",
            "40000/40000 [==============================] - 39s 977us/step - loss: 0.0176 - acc: 0.9944 - val_loss: 2.4473 - val_acc: 0.6491\n",
            "Epoch 99/100\n",
            "40000/40000 [==============================] - 39s 978us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 2.3585 - val_acc: 0.6568\n",
            "Epoch 100/100\n",
            "40000/40000 [==============================] - 39s 976us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 2.3956 - val_acc: 0.6586\n",
            "\n",
            "Epoch 00100: saving model to resnet50_cifar10_weights_0100_0.9996.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Lb6A0rlE6RWm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca945b86-7fb1-4a2c-f9a7-533597d4b8e6"
      },
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Acc', scores[1], 'Loss', scores[0])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc 0.6645 Loss 2.309853343009949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "737sqJ7JgCcP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "4d8d7a95-c003-4bfe-bad5-c612e501c82e"
      },
      "cell_type": "code",
      "source": [
        "epochs_list = [i+1 for i in range(epochs)]\n",
        "plt.figure(figsize=(14,8))\n",
        "plt.subplot(211)\n",
        "plt.plot(epochs_list, history.history['acc'], 'b-', label='Accuracy')\n",
        "plt.plot(epochs_list, history.history['val_acc'], 'r-', label='Val accuracy')\n",
        "plt.legend()\n",
        "plt.subplot(212)\n",
        "plt.plot(epochs_list, history.history['loss'], 'b-', label='Loss')\n",
        "plt.plot(epochs_list, history.history['val_loss'], 'r-', label='Val loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzAAAAHSCAYAAAAzGy67AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl8FdXdx/HPzN2yEhJI2HcQBAFl\nFVFQNven1qpg667VVqu1amtLH+Wp1qWKtZWqVatWRSta0dYNFFkUQVEElX1RtgAhCSHrTe4y8/xx\nSEIgkH2D7/v1mtfc5M69c+7MuXPPb85mua7rIiIiIiIi0gLYTZ0AERERERGR6lIAIyIiIiIiLYYC\nGBERERERaTEUwIiIiIiISIuhAEZERERERFoMBTAiIiIiItJieBt7h5mZ+Y29S5KT48jJKWr0/UrL\np7wjtaW8I3Wh/CO1pbwjddGc8k9qauJhnzsmamC8Xk9TJ0FaKOUdqS3lHakL5R+pLeUdqYuWkn+O\niQBGRERERESODgpgRERERESkxVAAIyIiIiIiLUa1ApgNGzYwYcIEZs6cechzS5Ys4aKLLmLy5Mk8\n/vjj9Z5AERERERGRUlUGMEVFRdx7772MGjWq0uf/+Mc/MmPGDP71r3/x6aefsmnTpnpPpIiIiIiI\nCFQjgPH7/TzzzDOkpaUd8tz27dtJSkqiQ4cO2LbN2LFjWbp0aYMkVEREREREpMp5YLxeL15v5Ztl\nZmaSkpJS9ndKSgrbt2+vv9SJiDQT0Sjs3m2xfbvNjh0WO3bYFBRA794OAwY49OnjEBPT1Kk8Orgu\nhMNmiUQgHLaIRCAUMv/LybHIybHYu9eq8Dgvz6J3b4fx4yOceKKDXcNeno4DRUVQWGhRWFi6tigo\ngIICi/x8i/x8yM+39v9ttolETP5wHAvHMY+jUbAsGDw4yumnRxk+PEogUPtjEgrBrl0W6ek2e/da\nlJSY/xUXW4RCUFJS/r9QqPx4mbX5G6BvX4cTT4xy0klRkpOr3q/rQm4uJCTAYYoCNeK65nNs3Giz\na5dFXBzExbnEx0N8vEt8vEtcHMTGuoTD1v7PYz6D+ZwQiVgkJbm0a+eQnGyOc23TkpVl8f33Ft99\nZ5OdbeHxmM9ZuvZ6XTz7R5U1ecHkjYKC8nxRVGQRDpv8U5oXolGrLB84zsGLVfZ/1z30+dL/ua75\nYJbl7l9TYV26Tfn2Zm0+W0LZZ3Td8s97IMsqX8B85iuvDHHXXaFaH9O6CoVg0yabNWtsNmywCQat\n/dcAcywjkfLvG4Btm3SbxS17XHouDvwuhMNW2XXFXFvK37v0OnPweTlwDZCS4tK2rVlSU8sfp6S4\nRCKUXSPy8qwK14ySErOv0qV0X5GIeX/brriUfrbERJfjj3cYMCDKCSc49O7t1Pl76DiQkWGV/Y6V\n/qalp9vs3Glx7bVw2WV120djaPSJLJOT45pkjOkjTYYjciTKO/XLcSr+aDY3rgtbt8KSJWb59lvz\n944d5T+alfF4oE8fGDQIBg6E44+HuLjECj9KHk/5j1NuLmRlQXa2WZcu2dnQvTtMnAjjx0OnTnX/\nPDk5kJHBAYXB8mAgFDLnpEMH6NoV0tKOfG4cB3btgu+/hy1bTIEyNrZ8iYkpfxwMQnp65cvevQcW\n9soLeqXrunj44QBt28KkSXD22XDmmZCaWn48tm2Db76Br78262++Mee3sLBu+63MokVeHnsM4uPh\n9NNNmiZNgr59y49zfj7s3GmWXbvMescO2L49ke3bYft2c/4OLoDWVc+eMHy4WU46CfLyzDktPbel\n6/x8SEkxx/J//sccz6SkI793NAqbN8Pq1bB2LaxbV74uKKi/zxAIQPv20LGjycMdO5pgq7xQW754\nvSbfbdpUvuQ3wNzatl0eBJUuB37/D74meL2H/t+2Tf4w59w6JAhx3fJtDl6bxaoQ8Bz4+MD3OPBx\nejr87W8BPJ4Ajz5a/Wv0l1/Cu+/Cvn2VL6GQua60bw/t2pl16ZKQYPJE6Xdx7VpzXWoMPt+hS+l5\nq+zYOg5kZsL69XXftwmOzT5Lz0llgWwkAvPnl78uEIABA2DwYPMbExNDhaC79DGY35Pdu821IyOj\n/PGePZTd0DhYYqJ5riWUeyzXrd4lccaMGSQnJ3PZAWHZjh07uP3225k1axYAf/vb32jdunWFbQ6W\nmdkAV4sqpKYmNsl+peVT3jE/Jnl5Frm55u5SXp5Z8vPNxTcujv13Tc1d1Lg4cwc1Nxe2bLHZssXm\n++/t/Y8ttm2zadXK5aabQlx1VZi4uJqnqbgY0tNLa0Nstm+32L3bJiHBpU2b8sXcHXNo08bF5zOv\nPfCOmnls8d13Fl984Slb9uwpv3VvWS7t27t07uzSubOzf3Hp0sUhLg7Wr7dZu9bcMVy71kN+fv1G\nZn37RhkzJsrYsRFOOSVKgrmxSjBozsu+fWYxAZG5i5aeXn43LT3dpqio+mkKBFw6dXLp1Ml8zg4d\nHHJyzHnbutUc85KSun3G0nNyYMGu/LGLbR9YqHDLfui9XvD7XZKSzJ3Q5GSzlD5OSHBZudLDRx95\nmD/fy+7d5jxalsvgwQ6BgMuaNYeeo1atXLp1c0hIMHnYrA+sFTD/S0wsXcyd0dLtTeHBrVBA9XhM\nwe2zzzwsXOhl4UIPGzaU37zr2NHU2O3ebR3x/Pj9Lh07mvNRum7b1iUQMOcqEAC/H2JiXPx+9i9u\nhePn95vHoRCsWuVh5UqblSs9rFzpISfn8PuOj3fp2tXsd80am127zPH0el1GjYpy5pkRJk2KkJJi\njuvq1eZ7sHq1h3XrDs13fr9Lr16mtrJ3b5O/SkpMzcbBNV/BYOn5Zv9ndMvWPp+phdu922LPHnv/\n2iISqX6+jI116d7doUcPhx49XHr0cGjXzsFxyu/wl94tj0ZNzVp8vDnnCQnsX5fnkdL8WVrgbUq1\n/d3KzLS48MJY1q/38LOfhfjDH0qO+FlcF557zsdddwUqPfYJCS5JSeb7m5VlajOPJC7O1Db07x+l\nf3+Hfv0cWrVyywr7Hs+Bj81rDr0BYs6fuYaY8+L3l187Sr8XnjrcRw+FYO9ei8xMi6wss2RnW/j9\n5lpy8DUiIcHktwPTXt08kpsLa9Z4WLXKZvXq8u9Wba7BcXGm1ig1tfz6fuBvWufODklJzavcc6RA\nqk4BDMC5557LU089Rfv27Zk8eTLTp0+nR48eh30fBTDSEhQVwauv+sjNjSEtrZju3R26d3fo0ME9\nYrOUoiLIzjYX6uRkU4iuj2YXdeW65gJ/cJOSUAiKiix27rTYubO84Juebv7etevIhauaat3aFBo2\nbbIpKLBITXW4+eYQV14ZJjb28Glftcrm3Xe9fPyxl23brAoBRn1r185hxAjT5Gf4cFNtX92mP+Yu\npsWaNTYZGXHk5JSUBUwHNiVxXfND16ZNeQG8TRuzTkw0QdHHH3tYtMjL0qWesnPg9ZptcnOtav2A\npaSYwmfnzg6pqS6xseU/5KWFQ5/P/ATs3l3ejGDHDousrEOPcUqKQ9euprDftat5HBPjUlxsUVxs\nmjMFg2ZdUmIKCh06mO+NWRzatXPr1JSqulwX1qyx+egjLwsWePj8cw+OY5r89e9fupiCUqdObqMU\nOtPTLRYtMgHN4sUeLAvatTMBcvv2Dmlp5nG7di79+8cSF1dA27YNlzZT22ixcqWHNWvs/YGcCc67\ndq3YPMt14dtvbebO9fLBB16+/vrwJUCfz6VPH3OMjz/eoW/fKL17O3Tr5tap4HgkjmOuvRkZJg+W\nBh3lzfvMOj4eevY0+bCmTQxbirqUefbsMUHMhg0ebropxN13Vx7ElJTAnXcGeOUVP23bOjz4YAnd\nu5uAIynJXMcO/u0rLDRB0p495hq+Z49pYtWzp2ki1b370XtO6lMkAps323z3nV2hFru0OVpp3k9J\nMcFKWpq5/pfe/KpKcyoz1ymAWbVqFX/6059IT0/H6/XSrl07xo0bR+fOnZk4cSJffPEF06dPB2DS\npElce+21R0yMAhhpzgoK4Lnn/Pz9775KC3CBgCm8de/u0rq1y9695XdfsrMrL+ynpJg7pqU1Au3a\nuYwfH2HMmGhZrUBVolFYvtzGcUwb/zZtjlyoyciwWLLEw5IlHpYu9bBxo13Wnrq62rQxBc/kZHNH\nKSmp/O6SWZt0ld4xLb+Dau6iJiZCjx5O2V3O7t0dWrc2752TA08+6eeZZ/wUFlqkpTncckuIyy83\ngYzrwldf2bzzjo933/WyZUv5nd9OnUwBq0sXUzDv0qW8pqCoqPx8HLyORKwDmgSUtym3LOjQwS0L\nWDp3rp8CY31dd0Ih+PJLT1lAs3evRevWppDQurU5F+Zvc85KA5YOHczd4doyzb8sdu2ySU42+T6x\n+bcqOKzCQnPuDxcoNzfN/Xdr926LDz7wMm+eh2DQon9/Uwgt7Q/m9zd1Co9ddc07GRkWP/xhLJs2\nefjlL0uYOrVin5jduy2uvjqW5cs9DB4c5Z//DNKpUz23b5Qm05yuPfVSA1NfFMBIc7RvH/zjH36e\nftrPvn0WrVq5XHddiPPOC/DNN8GyplClzaFyc8uv5jExFZsttWljmp/k5FQsRO/da1UIItq0cTj/\n/AgXXhhhxIjoIXeegkH4+GMP773n44MPPGRnl2/QurVpitG7t1l69XIoKoKlSz0sWeLl++/Lty2t\nlo+LK61Odyu0+Q0EzN3xTp2csqZDHTq4jVLQ27u3PJApKrJo185hwoQICxZ42bnTfIb4eJeJEyOc\nd16EceMi1b6L1NR03ZG6UP6R2qqPvLN7t8UFF8Tx3Xc2t91Wwp13miDmyy9trr46lowMm4suCvPI\nI8Ut5qaAVE9zuvYogGlGJ0PqX3a2abLTv7+pmaiJrCyLp57y8eyzfgoKLFJSHG64Icw114SO2BY0\nJ8f0PzDBSvXas0Yipt3sd9/ZvP22lzff9JbV8nTu7HDBBWHOOy/Cd9/ZvPeel/nzvWU1OmlpDmed\nFSExETZvtti0yQRTlbU7Tkx0GTkyyqhRUU45JcKgQU61a3qaSna2xRNPmPNQVGRGGDrzzAjnnRdm\n7Nhoi/yB1HVH6kL5R2qrvvLOrl0WP/hBHFu22NxxRwmdOrnceWeASAT+7/9KuOGGcJP395H615yu\nPQpgmtHJkENlZFj85z9eZs/2kZFhMXRolJEjo4wYYZojHNyONhqFFSts5s/3smCBl6++Km8eNWBA\nlNNOizJmTISTT44ecrc+Pd3i8889LFtm2sSvXWuaZaWmOtx4o+mLceBrGjLvRCKweLGH2bNNM6mD\nOxb37Olwzjlhzj47wtChhw4JGw7Dtm1mONJNm2x8Pjj5ZNNno6HamTe07GzToX7w4JbfBEXXHakL\n5R+prfrMO+nppiZm61bzA5Sc7PL000HGjj3CkIzSojWna48CmGZ0MsTIz4d33/Xyxhs+PvnEg+NY\neDymv8WBfU/i4tyygKZ9e5fFi00H2H37TGHf43EZMSLKSSc5fPutzbJlnrLOzV5v+Wt37LD5/HMP\n6enl7x0T43LSSVHOPz/CT35SeSfyxso7xcUwb56XDz/00q2bwznnROjb19HdrRZM1x2pC+Ufqa36\nzjs7dlhcfHEccXEuzz4bpHt39Xc5mjWna48CmGZ0Mo5ljgMffeTh1Vd9fPCBtyzQGDo0ykUXhTn/\n/AipqS5bt1asJTlw6FGATp0cxo2LcMYZpqalVavy54JB+OILD5984uGTT7ysXGlqWMD0ORkxwtTs\njBwZZdCgqu/yK+9IbSnvSF0o/0htNUTeiUabxxDR0vCa07XnSAFMMxjgVVqCUMjM6bFpk1nS0y1O\nOinKOedUDCAqU1wMr7/u48knfWzaZIKRPn2i/OhHES68MHzI3Zzu3V26d48webKZaWnvXhOU7Nxp\nc8opUY477vA1E7GxMGaMmTcDQuTmwooVHjp3dujVq3GGShURETmatNRmyXL0UgAjldq1y+KZZ3ys\nX+9h0yabbdssotGKpf/nn4c77nAZNy7CBReYCc0O7D+SnW3xz3/6ePZZMySxz+cyZUqY664LMXBg\n9ZtHpaTAmWdGgZq3uU1KgtNPV1tdERERkaOFAhg5xLp1NlOmxJYNY9umjcPQodH9w/W69O5tZixe\ntMjLW295mTPHx5w5PmJjXSZMiHDOORGWLTNNxYJBMyTxLbeUcN11Ydq3V9tZEREREak9BTBSwWef\nebj88lhycy1+97sSrroqRHJy5dsOGRLiV78KsX69zVtveXnrLR9vv20WgC5dHG64oYQf/zjcYubu\nEBEREZHmTQGMlHn3XS8//3kMkQjMmBEs64NSlb59He68M8RvfhNi1SqbefO89OjhcN55kUOGQBYR\nERERqQsVLwWA55/38bvfBYiJgZkzg4wbV/N+I5YFAwc6DBwYaoAUioiIiIgogDnmuS48+KCfRx8N\n0LatwyuvBDnxRKepkyUiIiIiUikFMMewggL43/8N8Morfrp3d3j11SJ69lQnexERERFpvhTAHOXW\nrLFZuNBDRoZNRoZ1wGKTn2/GMT7xxCgvvxwkNVXBi4iIiIg0bwpgjlKRCDz2mJ/p0/1EIhUnXGnT\nxqFzZ4f27V369XP49a9LNEqYiIiIiLQICmCOQt99Z3HTTbEsX+6hY0eHqVOL98/d4pKa6uL3N3UK\nRURERERqRwHMUcR14aWXfNx9d4CiIosLLwzz4IPFtG7d1CkTEREREakfCmCOEhkZFrfdFsOHH3pJ\nSnJ56qkgP/xh9eZxERERERFpKRTAHAXef9/LbbcFyM62GTMmwmOPFdOxozrki4iIiMjRx27qBEjt\nuS5Mn+7nyitjKSy0uP/+Yl57LajgRURERESOWqqBaaGCQbj11hjefNNH164OL74YpH9/TUApIiIi\nIke3agUw999/P19//TWWZTF16lQGDRpU9ty8efN48skn8fv9nHvuuVx22WUNllgxMjIsrrgilhUr\nPIwYEeH554s1h4uIiIiIHBOqbEK2bNkytm7dyqxZs7jvvvu47777yp5zHId7772XZ555hpdffpkF\nCxawe/fuBk3wse7bb23OPDOOFSs8XHJJmDfe0ASUIiIiInLsqDKAWbp0KRMmTACgV69e5ObmUlBQ\nAEBOTg6tWrUiJSUF27Y5+eSTWbJkScOm+Bj27rtezj8/jl27LO66q4QZM4oJBJo6VSIiIiIijafK\nACYrK4vk5OSyv1NSUsjMzCx7XFhYyJYtWwiHw3z++edkZWU1XGqPYY895ufqq2MBeP75Ym6+OYRl\nNXGiREREREQaWY078btueXMly7J48MEHmTp1KomJiXTu3LnK1ycnx+H1emq62zpLTU1s9H3Wl8cf\nhz/+Ebp0gf/+1+LEE2ObOknHlJacd6RpKe9IXSj/SG0p70hdtIT8U2UAk5aWVqFWZc+ePaSmppb9\nPWLECF555RUAHnnkETp16nTE98vJKaptWmstNTWRzMz8Rt9vfVi40MMvfxlL27Yu//lPEZ06ueyv\nAJNG0JLzjjQt5R2pC+UfqS3lHamL5pR/jhRIVdmEbPTo0cydOxeA1atXk5aWRkJCQtnz1113HdnZ\n2RQVFbFgwQJGjRpVD0kWgM2bLX7601g8HnjhhSCdO6uzvoiIiIgc26qsgRkyZAgDBgxgypQpWJbF\ntGnTmD17NomJiUycOJFLLrmEa665BsuyuP7660lJSWmMdB/19u2Dyy6LIzfXYsaMIMOHa44XERER\nERHLPbBTSyNoimqp5lQdVh2RCFx6aSyLFnn5xS9KuPvuUFMn6ZjV0vKONB/KO1IXyj9SW8o7UhfN\nKf/UqQmZNL677w6waJGXSZMi/P73Cl5EREREREopgGlmXnjBxz/+4ef446P8/e9BPI0/YJuIiIiI\nSLOlAKYZWbzYw+9+FyAlxeHFF4McMFaCiIiIiIigAKbZ2LHD4tprY7EsM1Flt24acUxERERE5GA1\nnshS6p/rwp13xpCTY/HQQ8WMGhVt6iSJiIiIiDRLqoFpBt55x8uHH3o57bQIV14ZburkiIiIiIg0\nWwpgmlheHkydGiAQcHnooWIsq6lTJCIiIiLSfCmAaWIPPBAgI8Pml78M0auX+r2IiIiIiByJApgm\ntGKFzXPP+ejdO8rNN2u+FxERERGRqiiAaSKRCNx+ewyuazF9egmBQFOnSERERESk+VMA00SeecbH\nqlUeLr00zCmnaNQxEREREZHqUADTBLZvt/jTnwK0aeMwbVpxUydHRERERKTF0Dwwjcx1YerUGIqK\nLB58sJiUlKZOkYiIiIhIy6EamEb23nte5s71Mnp0hMmTI02dHBERERGRFkUBTCPKzzdzvvj9Lg8/\nrDlfRERERERqSgFMI3r6aT+7dtncckuI3r0154uIiIiISE0pgGkkjgP/+pePuDiXG2/UnC8iIiIi\nIrWhAKaRfP65h23bbM47L0JCQlOnRkRERESkZVIA00hefdUHwJQp4SZOiYiIiIhIy6UAphEUFsJ/\n/+ulSxdHk1aKiIiIiNRBteaBuf/++/n666+xLIupU6cyaNCgsudefvll/vvf/2LbNieccAK///3v\nGyyxLdW773opLLS44YYQtkJGEREREZFaq7I4vWzZMrZu3cqsWbO47777uO+++8qeKygo4Nlnn+Xl\nl1/mX//6F5s3b2blypUNmuCWaNYs03zskkvUfExEREREpC6qDGCWLl3KhAkTAOjVqxe5ubkUFBQA\n4PP58Pl8FBUVEYlECAaDJCUlNWyKW5gdOywWL/YwYkSEnj01dLKIiIiISF1UGcBkZWWRnJxc9ndK\nSgqZmZkABAIBbrrpJiZMmMAZZ5zB4MGD6dGjR8OltgV6/XUfrmsxZUqkqZMiIiIiItLiVasPzIFc\nt7wWoaCggKeeeoo5c+aQkJDAlVdeybp16+jXr99hX5+cHIfX66ldausgNTWx0ffpuvDvf0NMDFxz\nTQxJSTGNngapu6bIO3J0UN6RulD+kdpS3pG6aAn5p8oAJi0tjaysrLK/9+zZQ2pqKgCbN2+mS5cu\npKSkADBs2DBWrVp1xAAmJ6eormmusdTURDIz8xt9v8uW2WzcGM+FF4YJhYrZX3ElLUhT5R1p+ZR3\npC6Uf6S2lHekLppT/jlSIFVlE7LRo0czd+5cAFavXk1aWhoJ+2di7NSpE5s3b6a4uBiAVatW0b17\n93pI8tGhtPP+5MnqvC8iIiIiUh+qrIEZMmQIAwYMYMqUKViWxbRp05g9ezaJiYlMnDiRa6+9liuu\nuAKPx8NJJ53EsGHDGiPdzV4wCG+95aNDB4cxYzT3i4iIiIhIfahWH5g77rijwt8HNhGbMmUKU6ZM\nqd9UHQXmzPGSn29x9dUhPI3f5UdERERE5KikaRUbyKuvljYf0+hjIiIiIiL1RQFMA9i1y2LRIg9D\nh0bp08dp6uSIiIiIiBw1FMA0gNdf9+E4ljrvi4iIiIjUMwUw9cx14bXXvAQCLhdcoABGRERERKQ+\nKYCpZytW2GzY4OGssyK0bt3UqREREREROboogKlnr7+uuV9ERERERBqKAph65Lowd66XpCSX00/X\n3C8iIiIiIvVNAUw9Wr/eZscOmzPOiOCt1gw7IiIiIiJSEwpg6tGHH5qoZfx4zf0iIiIiItIQFMDU\no48+8mBZLuPGqfmYiIiIiEhDUABTT3Jz4fPPPZx0kkNqqtvUyREREREROSopgKknixZ5iUYtJkxQ\n8zERERERkYaiAKaezJtn+r8ogBERERERaTgKYOqB48C8eR5SUx0GDXKaOjkiIiIiIkctBTD14Jtv\nbLKybMaPj2LriIqIiIiINBgVt+tB6fDJaj4mIiIiItKwFMDUg48+8uLxuJx+ugIYEREREZGGpACm\njjIzLVassBk5MkqrVk2dGhERERGRo5sCmDqaP9+D62r4ZBERERGRxqAApo7Kh0+ONnFKRERERESO\nft7qbHT//ffz9ddfY1kWU6dOZdCgQQBkZGRwxx13lG23fft2br/9ds4///yGSW0zE4nAggVeOnd2\n6NtXwyeLiIiIiDS0KgOYZcuWsXXrVmbNmsXmzZuZOnUqs2bNAqBdu3a89NJLAEQiES6//HLGjRvX\nsCluRr780kNensWFF4axrKZOjYiIiIjI0a/KJmRLly5lwoQJAPTq1Yvc3FwKCgoO2e7NN9/kzDPP\nJD4+vv5T2Ux9+KEH0PDJIiIiIiKNpcoAJisri+Tk5LK/U1JSyMzMPGS7119/nYsuuqh+U9fMzZvn\nJRBwOfVU9X8REREREWkM1eoDcyDXdQ/534oVK+jZsycJCQlVvj45OQ6v11PT3dZZampivb7ftm2w\ndi2cdRZ061a/7y3NS33nHTl2KO9IXSj/SG0p70hdtIT8U2UAk5aWRlZWVtnfe/bsITU1tcI2Cxcu\nZNSoUdXaYU5OUQ2TWHepqYlkZubX63u+9poPiGHs2GIyM8P1+t7SfDRE3pFjg/KO1IXyj9SW8o7U\nRXPKP0cKpKpsQjZ69Gjmzp0LwOrVq0lLSzukpuXbb7+lX79+dUxmy1I6fPL48er/IiIiIiLSWKqs\ngRkyZAgDBgxgypQpWJbFtGnTmD17NomJiUycOBGAzMxM2rRp0+CJbS6Ki+GTTzz07h2le/dDm9SJ\niIiIiEjDqFYfmAPnegEOqW15++236y9FLcCSJR6KiixNXikiIiIi0siqbEImh/roIxP3afhkERER\nEZHGpQCmFhYu9BAX53LyyaqBERERERFpTApgaignBzZu9DB0aBS/v6lTIyIiIiJybFEAU0NffWXm\nsBk+XLUvIiIiIiKNrcYTWR7rvvjCBDDDhimAERERkfpl5ezFt/gTrEiY0OnjcJNT6u/NXRcsq/7e\n7yhn5e7D98Xn+D5bimfTRkrOOY+SH14EPl9TJ+2YpwCmhpYvNwHMkCEKYERERI550ShWUSFWYSFW\nQQFWYUH5uqgIJzkFp1Nnoh07QVzcoa8vKcH35TJ8ixbgXzQf78oVWK6ZosH1eAiPHEXorHMoOfMc\nnB49q5UkK2cvng0b8G7agGfjBjyl6x3biZwwkND4SYQmTCJy4hCwj4LGOI6DlbsPOzsbKzsbqzho\nArVKFtfjhYAf1x8oW7uBGAgGI9brAAAgAElEQVT4sQoK8C37DN9nS0zQsnZ12bkACLz3NtE/3UfR\njTdTfOnllZ/PlqSoCHtfDtbevWa9bx9MOh38rZo6ZVWyXNdt1IlMmmJ2z/qaVdRxoE+fBNLSXJYu\nLayHlElz15xmpJWWRXmnCTjO0VEYQ/mnMVl5ucS89AKejeuJDBlG+JRTifbqffiaCtfFs2kj/g/n\n4v/oA3yfLcEKh6u1L6dNG6KduuB06ozTsSP2lu/xL/0Uq6jIvLXXS3jYCMJjz8D1egnMeQ/vV1+W\nFaIjffsROutcwkOHY+3Lwc7MxM7KxM7cY5asLLwZuyAr69B9t21LtH1HvOvWYEUiZf8LnTGB0MQz\nTW1P6+RaHMGDd+RgZWbi2bkDOz0dnCihcRPhoEnQa/qe9vZteNeuwbtuDZ51a7F378Lem42dlYWV\nsxcrWr83lt2YGMJDhhE+eRThkafgdOpM7PPPEPPyi1jFxTht2xL86c8JXvNT3KTWFV5r5eXiWbsW\n75pVeNevhXAENzERt1Ur3MREnMRWuImtcFu1wklpg9O5M26rpIarHXNdPKu+JfD+O/gXzMNOTzcB\nS3HxodtefDGZjz/bMOmoodTUxMM+pwCmBtautRk7Np7Jk8PMmFHJSZejjgoRUlvKO43H3r6N2Cdn\nEPvKSxT/aDIF0//S4pvJHJP5x3Wxd6abAuqmjVh5eftrMgpNbUbpuqiIaM9ehIePJDx8JNF+x4PH\nU+Pd2du3Efv0k8TMfAG7sKDCc9G0doRHjSZ88ikmoOnaDf/SxfjnfYB/3od4tm0p2zZ8wiCcjh1x\nExJw4xNw4+Jx4+NxExJxY2Ow9+7F3pmOZ8d27PQdeNJ3YAWDZa+PHNeX0NgzCI89g/App+ImVCy0\nWRkZBD6cg3/ue/gXLai80Lmfk5CI3aE9JT16Ee19HNE+xxHpfRzRPn1wU8yE41Z+Hr6FC/B/9AH+\neR/g2ZNhDr9tU/KjSyiY9kfctLTqHUTHIfDvWfjnzzOfcWc69q6dhwR0TnwCJRdcSPGPLycybMSR\nv5+Og2f1KvyffYpnzWq8a1fjXbcOq+jQG8dO69Y4bdriprTBadMWp6157MbGmuZyBy+4WJEolJRg\nhUogFMIq2b8OlYDHWxa0RAafRGWjNVmZmcT+40lin30GOy8XJyGR4suuhEAAz9rVeNesxrNje/WO\n34GfJSERp3Nnop0643TqYh736El4+Eicjp1q/H6Ew/g+W4J/zrsE5ryHZ/s2AFyfD6djJ5zkZNzk\nFJzkFNzkZFNTmJJC4uQfkZmYWvP9NQAFMPX0QzBzpo/bbovhoYeKueqq6t1tkZbtmCxESL1Q3ml4\nnjWrifvbXwi8+W+saBTX48GKRim65TYK//f/Gj4Brou9JwOnTVvw1m+L7Frln1AIe2+2KTzHJzTf\n2qhoFHv3Ljxbvsezbg3etWvxrl1t7qrn51X58tLzXMpJSDQ1J8NHmIDmuL44ae0qLXwCeFd+RewT\njxF4+z9Y0SjR9h0IXvczwmeMw7v8S3xLF+Nb8imejN2Vvt5plUTo9HGEJkwiNG5i9Qv7ZR/Axdq7\nF0/6dpy2qTUrnBYV4V+0AM/G9bht2prXp6bipKbhtE2F2Nia5R3Hwbv6W/zzPiDw1my8a1fjJLWm\n8PfTKL7i6iPmId/ST4m/63f4vllpPpZl4aS1w+nUCadjZ6L711buPmJe+1dZoT5yXF+Kf3wFxRdP\nwU1NNQHLurX4P/0Y3+JP8C1djL1vX/nh8vmI9j6OyPHHEzl+ANF+/Yn07YfTqXOT9kWx8vOIeeF5\nYv/+t7IgEMBJTSPSfwCR4wcQ6T+A6PH9cePisfJysfLzsfLzsPPzzd95eaYGLX0Hnh07sNN3YOfl\nHrKvaJeuhEecTHjkKMIjRxHt26/83ESj2Bm7sbdtw7N9K57t2/BsWGeCyv3H0WmVZPLr2ecSGjcB\nN/HwTcSa02+XAph6Ohm33hrglVf8zJ9fyAknOPWQMmnumtMXWVqWZpd3ioshJqapU1EvvJ8tJW7G\nnwl8OBeASL/jKbrpl4THnkHSBefg/W4zBfc+QPCGm6r3hiUlWIUFZXeoq+Q4+Oe+T9yjD+FbuQLX\n7yfaqzeRPn2J9jmO6HF9zeNevSE2tlaf8Uj5x8rdt79fw0a8Gzfg2bje/L3l+4oF+/gEUyuQkGCa\nryS1JjxkKOFRpxIePhLi42uVtmopLsa76hu869dhb99mah92bDfrnellTZhKuR6POYb9+hPtdzyR\nvv1wWyeX12rEx5cHZh4Pno0b8H3xOd4vPsf35TK8GzcckgSnbVuctPY47dsTbd8Bp107fJ8txb/0\nUwAi/U+g6Oe/MJ2yDw52XBfP95vxLfkU35LFeLZuIXzyKYQmTCI8bESz7sRd62tPNErMP58l/v57\nsPPzCA8dRv5DfyE6cFCFzewt35Nwz90E3vkPAMU/uoSiX/2aaPcehw0aiUbxfbyQmFdeIvD+O1ih\nkGkuN+JkvOvXYmdnl2/apSvh0acRGn0akROHEO3Zq1kfb4qL8X/0IW6rVkSOH4Dbtm2d3s7Kz8NO\nT8eTvh3PmjX4vvgM37LPsPfuLdvGSWpNtG8/7D0Z2Ok7Km3CGO3U2fSdOutcwqNGH/7cHKQ5/XYp\ngKmnk3HqqXHs2GGzeXNBbWqrpQVqTl9kaWSOQ9xfH8G3cP7+O51tzV3O/Xc6ndQ0nO7dcdq1r/Tl\nzSLvOA7+998l7m9/wbf8C9MGvmdvIr16E+3Vm2jP/evuPWpd0K4N77LP8c//wNx9LCgwdyULSpcC\nrGAQ1+sF//6Otj4frt8PPj/WvpyyO77hESdTdMuvCE04s+xupL1tK63PnYgnYzd5f3+WkgsvPmJa\nfPM/JPGWG7Ez9xA+5VRKfnQJJef9T+V9AaJRAu/8h7hHp+NdswrXsgifdjpWfi6eDRsOaYbk2jaR\nIcPMnc/xE4kMHFy9WpHCQlILssj9eo0p/G/bhmf7NvN4+9YKBZlSTnIy0T59iXbsiBUM7j+mBaYw\nVFBgju0BzZZcr5fI4JNMM6lTRhMeOQrX6zPnJC/X3B3OzcXOz8PKy8ONiTFNdVJTTf5v07a8QOQ4\neL7bjPerL/F99SXeFcvxrvr2kEKVa1k47dqbDu1duuB07U6kbz9zV713nzoF2NbebHzLv8C7/As8\nW7eaO9K7d2Hv3o1dUPF7GDpjPEU33kJ4zOktvqlhZep67bEzdhM/bSoxs/+Na9sEf/pziu6caq6J\nj04n9pknsUIhwsNGUHDvA0SGDq/R+1t7s4l54zViXn4J75pVRDt2MgHLqWMIjz4Np2u3Wqf9qLW/\n35Xv86Vli2fL90TT2uF06Uq0a1ecLt2IdulKtEtXnG7diPY8Qj+uI2gWv137KYCph5ORmwt9+iRy\n6qkRZs8OVv0COSo0py+yNKLCQlrd+FMC779zxM1cy6L4sisp/O1dpinEAWqTd3xLFhP36MO4cfGU\nXHAhJZPOrt1d8pISYl5/ldjH/4p38yYA0+l3bzaebVsP6ezq2jaRocMJjZtAaNwE0/a7AZof2Vu+\nJ/6P/0fMf9+s9HnX5zM1BbFxEA5jhUMQCmOFSioUhksmnUXRL35F5ORRlb6PZ/UqWv/PWVjFQXJn\nvkb4jPGHbhQMEn/v3cT94ylcn4/IwEH4vlpu0uH3Exo/ieKLLiE08SzwegnMfp24vz6Cd+MG01fg\nhxdRdOsdpikHmOZku3biWb8O78b1ZgSo1d/gXfEVlmNq7J3UNHOMx08kdPo4UyjZsMFsX/q6jRvK\n2qofcnxiYkwBpWs3E6z0Ke/jUJ27vlZerhlhacmn+JYuNqNd1aHjs9MqCadtW+zsbOzcik1+IicM\nJDJkGJGBg02aO3cxTaUCgVrvr9YKCvDs2Y29axdOu/YmWDqK1dfvlm/hfBLuvA3v998R7dARKxzC\nzsoi2rkLhXf9gZILflS3ANB1sfblmJsFR2Eg2eCi0Vr1/apKcyr3KICph5Mxf76HKVPiuPXWEqZO\nDdVTyqS5a05f5Mbm+2wJsX99BMtxcFolmYJlYquykVScVkmmer9vvyb/8fEu+5yY2a8RHj6Skh9c\nWKf+CPbOdFpdPgXft18TOnUMeU//0xROy0b5KR3xJxP/B+/jXb8OJ7EVRbffSfC6G8ruStck79jf\nf0fCH+4i8N7bFf7vxsVRMuksSi64iNC4CVXeobbycon553PEPv0Enj0ZuD4fxRdNJnjTL4ke19ds\nFArh2bYVz+ZN+5eNZqScAwvabdoQOn28KWyfPv6Q4KymrLzcinduhw6j6LbfEO3QyeSnhETchIQj\nF25dF8JhM9JYNe7U+5YsJmnyD8HjZd+b7xA5aWjZc55vv6HVz6/Fu2E9keP6kvfks0QHDsLetpXA\nW28Q88ZreNeuMccisRVu69Z4tm/D9XopvuRSgrf8ytzdrM5nz9mLf9EC/B99aNqkZ+4xH8eyKgzP\nWiqa1o7ocX3x9+9HQVpHc3e1S1eiXbqZvhb1+V0rKDDD9y5djG/5cvDY5rveKsmMlpSUtH+0pESs\n4mLs7CysrP2jXmVl719n4iQkmGBlyFDCQ4YROWFQ0wQqAtTz71ZxMXEzHiXur4+A10fRrbdTdMNN\njVpjK42rOZV7FMDUw8l46CE/06cHmDmziEmTNAfMsaI5fZEbTTBI/P33EPv0E5UWsA4W6dmL0Nnn\nUXL2eUSGDW/UjsPe5V8Q/9D9+Bd8VPa/aPceFN38K4ovubTGhSjvyq9odfkUPBm7CV5+FQUPPnLk\ntteRCDEvPEv8n+7D3rePSM9eFP7hfkKTziI1rVWVecfKyyXuzw8T+4+/m4L98JEU3PsAbmwcgf+8\nQeDNN/B+/x1gCtKhs88lMnDQ/tGYCk2zoAPmnvB+tRw7P8+MinPF1QRvuBGnQ8dqfXYrZy/+jxfi\nmz8P//x5FTowu34/eH24Ph/4vLg+v2nW5fXidOpMZOBgIgMHERl0ommvXnpXMBIh5qV/Ev/QfdjZ\n2fV357aa/O/8l1bXXYGbnMy+dz8k2r0nsU/MIP6Be7DCYYquu4HCu+6ptDDmWb2KmNmvE5j9Onbm\nHoovvZyim2+tW/MWx8G76hv8H32I75NFpkalT1+iffsR2d93pnQ41mPy2iP1oiHyjr17F67Pj9um\nmv3EpMVqTtceBTD1cDImT45lwQIva9YU0LZtox4yaUJN/UUu7cxn79yBZ9cuIv2Or3F745rwLv+C\nxJt/hnfTRiI9e5H/2N+JnDAQKz/ftIXf3x7eys/Hzs7C//FC/B99WDa8pZOaRslZ51Jy7nm4qWlm\nVJQd2w5px4/fR2jsuFrf4feu/Iq4h+4nMO8DAEKnjSX405/jn/cBMa/OxAqFiHboSPCmWwhedlW1\nJhvzv/0WrX5xAxQXU/iH+0wH8GoWsq292cQ//AAx/3wWKxolNPYM/I/PIDO1S+XvEYkQM/MFU7DP\nyiLapasp2P/gworbuy7eb78m8OYbBP4zu8qhOaPt2hP86c8ovvKaQ+YlqBHXxbNmNf758/AvXoSV\nlwvhiGnGFQmbdTiMFQqV1SiUvTQujsiAgUROGIhvyWJTQxWfQNGttxO8/sZGv3Mb88JzJP76VtPs\nqktX/J9+QjStHfmPPUF43MSq38BxTFONRu5E3NTXHmm5lHekLppT/lEAU8eT4Thw3HEJtGnj8vnn\nmsDyWNKYX2TvNysJzHoF76aN2DvTTeBScOi+Q6eNpehXvyY8+rTqFbBLSrD3ZuO073D47UtKiJ/+\nILEzHsVyHIqu/zmFU6dVb5bhYBD/Jwvxv/8ugbnvYVcygVopNy6eaLduWDk5eHbvMv+zLCKDTzTB\nzBkTiQwdZpqAlY7bH42aL6Hj4N24nrjpDxKY8545FqNGU/SbqeZY7Gfv3kXsEzOIffE5Mwt2mzYE\nb7iJ0LgJOEmtcZOTzTwLpTVFrkvcX6YT/8C9OPEJ5D/1LKFJZ1f9uSvhWbeWhLt+i3/RgrLPRkwM\nbiCAGxMLgQBubCxWfj6e9B01K9g7Dt4Vy7F37SofWapsdCbzN35/ozfns/Lz8K5ehfeblXi/+Rrv\nt9/g2bDODGts2xT/5AoK7/zfmg81W4/ipj9I/EP3A1By9nnkP/JYnUcKamjNqRAhLYvyjtRFc8o/\nCmDqeDLWr7c57bR4Lr44zOOPawLLY0mDf5FLSgi8/Raxzz2D78tlZf92klrjdOxItKMZR9/p1Akn\nNY3A22/hXzgfgPCwERTd9mtC4ycdUmi19mabcf3nvIdvwUfYhQU4CYlmeNLj9w9T2q8/keMH4NmV\nTuIvfoZ37WqiXbuR/9cnKgQENRKN4vvic/xz3sMqDhLt2t2MiNLVtON3k1NMWl0Xz9o15g7/gnkV\nZrJ293+WIzVfCw8fSeGdvyd82tjDFtit7Gxin3mS2GefrtDBGEyndbd1a5yk1uDz4d2wnmjnLuS+\nNIvogBNq99nL3tzF/8Eckl59kVB2DlZxEKukxIwAVVKCVVIMkSgl5//AdP5v165u+2uOgkG869bg\ntE7G6dGzqVMDrkvMc8/gtm5tRiVrAR2Gm1MhQloW5R2pi+aUfxTA1PFkvPKKl1tvjeXBB4u55hpN\nYHm0szIy8K1YjnflcuL3ZlKSlWNmf64wI3QBTqskSi6eQvGPL692P4NSdvoOYl54jtiZL2BnZeJa\nFqHxEym++jrCo0YfMhPzgbwrlhP36HQCc94FIDxwsBmDv39//HPn4J/zLr7Pl5Z1yI706Em0/wl4\nNm80s1sfNP9CqeAV11D4f/cecd8NpqAA/6ef4P/oA7xr15ggxrbNYtlgm7/d+ASCl11pRpWqbvOu\n/DwCr/0Lz5bvsXNysHL3la2tffuw9+UQHj6SvL8/V6+1BM3pR0BaHuUfqS3lHamL5pR/FMDU8WTc\ndluAmTP9fPRRIQMHagLLo0pBAb6VX+H9avn+oOUrPOk7Kt3UtW0zWlJ8PG5CAp70dKyiQlzbJjRh\nEsWXXUVowqTKR8AqKcG7+lu8K5bjX7QQ/wfvm9G9Wrem+NLLCV51bY3vVHtWryLur9MJ/OfNCrUV\nrmURGTqckrPOJXTWOUT7HFde2A+FzOR369bgWWdmv7Zycym69Q7C4ybUaP9yZM3pR0BaHuUfqS3l\nHamL5pR/FMDU8WSMGRPHtm02mzYV1GV0VmlmAm+8RsKdt2Pn5Zb9z2mbSnjIUCInDSV80hBaDxtM\nVoll+hfExFS4628V5BN48w1iZv4T34qvAIi270DxpT8hNPEsM+nUiuVmUrfVqyrMYxEeOJjia6+n\n+IIfVa+fyRF4Nm0k9skZ2Hv3EpowiZKJZzVpfwMxmtOPgLQ8yj9SW8o7UhfNKf/UOYC5//77+frr\nr7Esi6lTpzJo0KCy53bt2sVtt91GOBymf//+3HPPPUd8r5YWwOTlQZ8+CYwaFeWttzSBZbPkONjp\nO3A6da7WEL5W7j4S7ryNmNn/xolPoPiKqwkPG0HkpCHmPQ4IUqqbdzyrviV25j8J/Pu1CgERmCFo\nIwNO2B8UDSUyZJiZSK0FtMOX2mtOPwLS8ij/SG0p70hdNKf8c6QApsr6hGXLlrF161ZmzZrF5s2b\nmTp1KrNmzSp7/sEHH+Saa65h4sSJ/OEPf2Dnzp107Fiz/gDN2VdfeXBdi2HDNPdLtezvLGsVFxM9\nzswQ7XTt1iCzxQL4Fn9M/B/uwvf1CiK9+xC8/kYz/8dhajV8n35C4i9uwJO+g/CwEeQ9/nS9dDKO\nnjCQggcfoeDuewm8/Ra+5V8Q6Xs8kSFDifQ/QZO6iYiIiNSTKgOYpUuXMmGCaRvfq1cvcnNzKSgo\nICEhAcdxWL58OX/+858BmDZtWsOmtgl8+aUpeCuAqZ7Yf/ydhN/fWeF/rt9PtFdvor2PI9KnD07H\nzuUzPCeZWZ+dVkm4SUnVmmEbwLN2DfH33l02D0h45Ci8X31J4m9+RfwD91B8xTUEr73eDB0MEAoR\n/+AfiX38r2DbFP5mKkW33lGnGdsrFRdHyeQfUzL5x/X7viIiIiICVCOAycrKYsCAAWV/p6SkkJmZ\nSUJCAnv37iU+Pp4HHniA1atXM2zYMG6//fYjvl9ychxeb8PcjT+SI1VDHcm335r1mWfGUcO59o49\ny5fDH+6C1FT461/h++9h3TqstWvxrluHd+0aqqyHSEmB0aPhtNPMMmSImduiVHo6TJsGzz9v5gY5\n/XR4+GF8w4bB7t3wxBPYTzxB3F8fIe6Jx2DyZLj4YvOalSuhVy+YOZP4k08mvpofq7Z5R0R5R+pC\n+UdqS3lH6qIl5J8a334+sMuM67pkZGRwxRVX0KlTJ66//noWLlzI6aefftjX5+QU1SqhdVHb9nyO\nA0uXJtCtm4tlFZKZ2QCJO0pY+XkkX3QxnlCIfX972gxzeyDXxd69C8+G9dh7MrDy8rDzcs2s7vvX\ndu4+PN9txvP22/D22+ZlsbGEhwwjPHIUViRC7DNPYgWDRPodT+Hd95TPgZKZD554uPnXcN0viPn3\nLGKfehzvzJkwcyYAwZ9cQcG9D0JCgtm+GppTW1BpWZR3pC6Uf6S2lHekLppT/qlTH5i0tDSyDphZ\ne8+ePaTur4pITk6mY8eOdO3aFYBRo0axcePGIwYwLcnmzTb79lmMH1/5vBlHMysvF9/iTwiNn1h1\n/w3XJeH2W/Bs+Z6iX95+aPACYFk4HTpWa74Ue2c6vs+W4Pt8Kb7PluJbshj/p58AEG3XnqL7H6Z4\n8o8P3/wrNpbiy6+i+CdX4Fv4ETGvz6Lk/AsInXNelfsWERERkeatygBm9OjRzJgxgylTprB69WrS\n0tJISEgwL/Z66dKlC1u2bKF79+6sXr2ac889t8ET3ViWLzcjWrX4/i+uW6MRr/xz3iPhN7/Cs3sX\n4SFDyfvHiziduxx2+5iZLxDz1uyy2dHryunYiZILLzYzZgPWvhx8yz7D2ruXkvMvgPhqNv6ybcLj\nJhIeN7HOaRIRERGR5qHKAGbIkCEMGDCAKVOmYFkW06ZNY/bs2SQmJjJx4kSmTp3Kb3/7W1zX5bjj\njmPcuHGNke5G8cUXzaQDf0EB8Q/cQ7Rff4ovvazaHc99C+eTMPXX2BkZFF95DcEbbsRp1/6w21t7\n9pDw+98Q85/ZuH4/odGn4f/0E5InnEbeE/+odKJDz5rVJPz+NzitW5P31HP13ykecFsnE5p0dr2/\nr4iIiIi0PJrI8gjGjo1jyxYzgaXP1wAJq47CQpJ+cjH+JYsBiPTtR+G0e8v7flTC3r2L+Lt/R8xb\ns83s8cnJ2NnZuH4/xRdPIXjTL808JKVcl8CsV0i4+3fY+/YRHj6S/D/PIHpcX2JefJ6E3/8GwmGK\nbvsNRXf8tnxI5MJCkieNxbtxA7kvvkrorHMa+mg0uubUFlRaFuUdqQvlH6kt5R2pi+aUf47UB6bq\nWf+OUQUFsG6dzeDB0aYLXoqKSLpiCv4liyk553yCl12JZ+MGkn58MUkXX4Dn228qbh+JEPv0EySf\nMsw06Ro6jH0fLiJ7xVryH3mMaOcuxL78Ismjh9Hqqp/g/XIZ9tYtJF1yAa1u+TmEI+Q/8DD73p5L\ntG8/sCyKr7yGfe98gNO5C/GP/ImkS3+ElZ0NQMLUX+PduIGiG248KoMXEREREWl+6r+9z1GiySew\nDAZJuuJS/J8souSc88l75p/g8xG87mck3HMX/vnzSJ5wGiWTf0zh7+7CTt9Bwm9uw7fqG5zWrcmf\n/leKL7uybGb64suvovjHl+N/7x3i/vYogffeJvDe27heL1YkQsn4iRQ8/JdK+7pEThxCzryPSfzF\nDQQ+nEvy+FMpvuRSYv81k/Dgkyj83z808sERERERkWOVamAOo3wCS6fxd15cTNLVP8H/8QJKzjyb\nvKefp7QaKNp/ALmvzmbfrDeJ9utPzKsvkzLyRFqfOxHfqm8onvIT9i75iuIrri4LXsp4PITO/wH7\n5ixg35vvUjJ+ItEePcl78h/kvfLvI3bUd5NTyHtpFoVT7zZN1P4yHSch0aRNs8yLiIiISCNRDcxh\nLF9uApihQ2tYA1NSgrVvH267drXbcUkJra65DP/8eZRMPJO8f7xYcSLH/cJnjCdnzOnEzHqFuAf/\niJucTMGf/kz45FOq3odlER59GuHRp9UsbbZN0a13EB4yjPgH/0jRL2/H6dGzZu8hIiIiIlIHCmAq\n4bpmCOWuXR3atavZGAcJU39NzMwXKLrjtxTd9pvyDu/VEQrR6rorCMz7gNC4CeQ9+9KRazc8Hop/\nfDnFU35iOvTXYKjkugiPOZ19Y05vlH2JiIiIiBxITcgqkZ1tsXevTf/+Nax9CQYJzP43lusS//AD\nJE2+EGvPnmq91MrPo9VPryIw931CY88g9/mXISamevu17UYLXkREREREmpICmEps3WqCgW7dalb7\n4p8/D7uwgODlV1Fy5tn4P15A8rjR+PbPIl8ZKz+PuL9MJ2XYQALvv0PotLHkvvAviI2t02cQERER\nETkaKYCpxNat5rB0716zDvyBt98EoPiKq8l78VUKpv0ROzuLpB+dT9yfHwKn/P2s/DziHn2YlKEn\nEH//PeC6FP72f8md+RrExdXfhxEREREROYqoD0wlahXABIP4584h2rU7kUEngmURvOkWwsNH0ur6\nq4h/8I/4PltC/p/+TMxbbxD75AzsfftwWrem8Hd3EbzuBtzEVg30iUREREREjg4KYCqxZYsJYLp1\nq34AU9p8rOian1bojxIZMZKc+YvNHCrzPqDNyBMBcJKTKZx6N8Frr1fgIiIiIiJSTQpgKrF1q4Vl\nuXTuXP0+MKXNx0r+54JDnnNT2pA38zViH3+MmJdfoGTKTxS4iIiIiIjUggKYSmzdatOhg1vtQcAI\nBgnMeZ9ot/3Nxypj2wRvvpXgzbfWWzpFRERERI416sR/kJIS2LnTqlH/F//8eVhFhZT8zw81nLGI\niIiISANSAHOQHTssXCdCbRYAACAASURBVNeq0RDKgf/OBipvPiYiIiIiIvVHAcxBatyBPxgkMHfO\nkZuPiYiIiIhIvVAAc5CaBjBqPiYiIiIi0ngUwBykdA6Y6gYwZc3HfvDDBkuTiIiIiIgYCmAOsnWr\nqUXp3r0afWAObD42cHADp0xERERERBTAHGTrVpv4eJc2baoOYPwffWiaj/3gQjUfExERERFpBApg\nDuC6JoDp1s2pVjxypMkrRURERESk/lVrIsv777+fr7/+GsuymDp1KoMGDSp7bty4cbRv3x6PxwPA\n9OnTadeuXcOktoFlZVkUFlrV6/9S2nysew81HxMRERERaSRVBjDLli1j69atzJo1i82bNzN16lRm\nzZpVYZtnnnmG+Pj4BktkYynt/1KdOWDKmo9p9DERERERkUZTZROypUuXMmHCBAB69epFbm4uBQUF\nDZ6wplA6Aln37lXXwKj5mIiIiIhI46uyBiYrK4sBAwaU/Z2SkkJmZiYJCQll/5s2bRrp6ekMHTqU\n22+/HesINRLJyXF4vZ46JrvmUlMTq9wmK8usBw+OITU15vAbBoPwwRzo1YvkcaeqBuYoV528I1IZ\n5R2pC+UfqS3lHamLlpB/qtUH5kCuW7F51S233MJpp51GUlISN910E3PnzuWss8467Otzcopqnso6\nSk1NJDMzv8rt1qyJAXy0bl1AZubhm5H53/kvSYWFFJ37Awqzjs7aKDGqm3dEDqa8I3Wh/CO1pbwj\nddGc8s+RAqkqA5i0tDSySqsmgD179pCamlr29wUXlDehGjNmDBs2bDhiANOcbdliYVkunTu7UFCA\n5/vvsLOzsLMyzZKdjZWVie+zJYAmrxQRERERaWxVBjCjR49mxowZTJkyhdWrV5OWllbWfCw/P59b\nb72VJ598Er/fzxdffMGZZ57Z4IluKFu32nTs6BKwQqSMHoZn187DbhsePpLICYMO+7yIiIiIiNS/\nKgOYIUOGMGDAAKZMmYJlWUybNo3Zs2eTmJjIxIkTGTNmDJMnTyYQCNC/f/8WW/tSXAy7dlmcckoU\n36ef4Nm1k/CIkwmNm4DTpi1O21Sctqm4bduYdask9X0REREREWlk1eoDc8cd/8/efcc3Uf8PHH9d\nZps2HUCLyhYQENkbERQEwYGgMmUoKMhQcFAEZcoeKgoCMpVZ9lIREFmyQQH9MgRlr7a0TZu2mff7\nI/yqSBcdNIH38/Hog/ZyuXsneXO5933GfXDL3+XLl0/9vWvXrnTt2jV3o8oHFy8qqKrnHjDGHzYA\nYB00BMfjT+RzZEIIIYQQQoj/l+k0yveL1CmUi7swbPwed2gojjr18jkqIYQQQgghxL9JAXPT2bOe\nt6KGegDt1SvYm7UA3R1P0iaEEEIIIYTIQ1LA3PT/BUyVs+sBsLV4Pj/DEUIIIYQQQqRBCpibzp3z\nDMgvenADqr8/9icb53NEQgghhBBCiP+SAuamc+c0VDWdxHjmBPZGjcFkyu+QhBBCCCGEEP8hBQyg\nqp4CppN5DQC2Z6X7mBBCCCGEyF+bN2+kUaM6xMXF5XcoXkUKGCAqSiEpSaGFfS2qRoO9qW/ey0YI\nIYQQQtw7Nm/+kSJFirJt25b8DsWrSAGDZ/xLYa5SPnYvjrr1UQsWzO+QhBBCCCHEfcxiief48T/o\n2/ddtmzZBMCpUyfo2fN1evXqxrRpU9Jd1rdvD/766zQAK1dGMmfOTA4fPkhERH/69u3BiRPHWbJk\nIT17vs6bb3Zl7tyvb+7TwoAB/ejd+w0iIvqTmJhI27YvkpSUBMDRo78xePCAu/1W3EbmCcbTfewF\n1qNBxd7iufwORwghhBBCeInhw42sX5+7p8wvvOBk+HBbhuts3bqF+vUbUKdOPcaPH0VU1HU+/3wS\nAwYMpkyZsnzyyVCuXr2S5rL0nDlzmiVLVmEwGPj110N89dVsNBoNbdu+SLt2HVm4cCm1a9ejTZv2\nREYu4vDhgzRs+BS7du2gWbPm7Nq1naZNn8nV9yI7pIDBU8C04ub4l+ZSwAghhBBCiPy1ZcuPdO3a\nHa1Wy1NPNeGnnzZx/vw5ypQpC8CQISMB0lyWnjJlymIwGADw8/Ojb98eaLVa4uLisFgs/O9//6NL\nlzcBaNfuVQAeeqgIs2dPp1mz5vz66yG6d38rT17vnZACBrh22srTbMFathLuEiXzOxwhhBBCCOEl\nhg+3ZdpaktuuX7/G//73O1Onfo6iKKSkpGA2B6LR3D76I61liqKk/u50OlN/1+v1AFy9eoXIyEXM\nnbsIk8lE585tAdBqtaiq+5ZtlSlTlpiYGI4f/4NSpUpjNBpz5TXmhIyBAR46tgkjdlzPS+uLEEII\nIYTIX1u2/Ejr1m345pslzJ+/mCVLVmKxWChRoiR//PE7AGPHjuTs2b8pWbLUbcsCAgKIiYkG4Nix\nI7dtPy4ujtDQUEwmEydPnuDq1as4HA4ee+wxDh06AMCaNSv54YcNADRu3JRPPx1PUy+Z6EpaYIAa\n59cB4Hxepk8WQgghhBD5a8uWH/n44xGpfyuKQosWz+N2u5k69TMAKlasRMmSpejX7wMmTRp7y7KW\nLV9i8uQJFCtWjCJFit62/bJlH8Hf30SvXt2oVKkqL774EpMnj2fmzK/o3/89+vbtgckUwPDhowBo\n0qQpS5cupEaNWnfh1WdOUVVVvZs7jIpKuJu7AyAszJzuflMsdsxlSpNsDEF3/ij8q8lNiIxyR4iM\nSO6InJD8EdkluSNyIr38+e67dVy9eoXu3Xve1VjSc993IbOs300I8Rwp+YIUL0IIIYQQQvzL+PGj\n2LTpBzp06JTfoaS677uQ6b/39O27WPMFauRzLEIIIYQQQniTgQM/zu8QbnN/t8C43TywbwMxFEB9\nvF5+RyOEEEIIIYTIxH1dwOiO/EqQ5TLreYHiD9/Xb4UQQgghhBA+4b4+azf88B0Aa2hFyZLuTNYW\nQgghhBBC5Lf7uoAx/rCBZMWfPYFNCQ3N72iEEEIIIYQQmclSATNmzBjatWtH+/btOXr0aJrrTJ48\nmc6dO+dqcHlJiY5Gd/IEP2maEl7STyYgE0IIIYQQXqFnz9c5ceL4LctmzJjKkiUL01z/8OGDfPxx\nxN0IzStkWsDs37+fc+fOERkZyejRoxk9evRt65w+fZoDBw7kSYB5RQ0N5eoHo/nANZ4SJaT7mBBC\nCCGE8A5Nmz7D1q2bb1m2bdtWnn66WT5F5F0yLWD27NnD008/DUDp0qWJj48nMTHxlnXGjRvHu+++\nmzcR5hWtlkNP9uMk5SlR4q7ey1MIIYQQQoh0NWnSjB07fk79+8SJ44SFhREWFs6BA/vo2fN1+vbt\nwaBB7+NwONLchtPpZMSIj+nbtwfdu3fml192AnDq1Al69nydXr26MW3alFuWtW/fPnVZ3749+Ouv\n0wCsXBnJnDkzOXz4IBER/enbtwcnThxnyZKF9Oz5Om++2ZW5c78GICEhgQED+tG79xtERPQnMTGR\ntm1fJCkpCYCjR39j8OABOXp/Mr0PTHR0NBUrVkz9u0CBAkRFRREYGAjAqlWrqF27NkWKFMnSDkND\nTeh02myGm31p3c0zNtbzb6VKBsLCDHc5IuErMroTrBAZkdwROSH5I7JLcieXDRgAy5fn7jbbtIGJ\nE9N9OCzMTMmSJbhy5W8qV67M/PnbeemlVoSFmVEUB1OmfEaxYsWIiIjgxInfCAkJwGjU3/LZx8TE\n0KTJk7Ru3ZoLFy7Qr18/WrV6ln79PmPMmFGUL1+eiIgI7HYL06bdvsxg0BEaGkBYmJnAQD8cDiMh\nISbOnv2LH3/8EYPBwJ9//s7y5ZFoNBqaNGlCnz49WbgwksaNn6RLly7Mnz+fM2f+oHnzZzh6dD8v\nvPAChw7t4eWXW+UoT+/4Rpaq+k9rRVxcHKtWrWLevHlcu3YtS8+PjU26013mWFiYmaiohNuWHztm\nAIwUKJBEVJTrrsclvF96uSNEZiR3RE5I/ojsktzJfQFJdozu3O2tY0uyY83kc2rU6GlWrFjDgw+W\nYvPmLUyfPpeoqAQ0Gj8GDhyEy+Xi8uVLVKxYlQceeBCbzXHLZ+90ati//xCLFi1GUTTExNwgKiqB\nM2f+omDBIkRFJTBgwBCA1GVA6jK73UlsrJWoqAQSE1OwWm3ExSVRqlRp4uNtgA2nU6Fduw5otVpu\n3Ijlr78u8dtvR3njjV5ERSXw3HMve97DgALMnj2dunWfZPfuPXTs2C3TPM2owMm0gAkPDyc6Ojr1\n7+vXrxMWFgbA3r17uXHjBq+++ip2u53z588zZswYBg8enNlmvcK5c54edDIGRgghhBBCpMU6fBTW\n4aPu+n4bNXqKb7+dS9Omz1CsWHGCgoIAGDv2EyZO/JySJUvx6afj033+5s0bsVgsTJs2G4vFwhtv\neCbb0mhuH0GS1jLlXzNcOZ3O1N/1ej0AV69eITJyEXPnLsJkMtG5c9ub29KiqreeW5cpU5aYmBiO\nH/+DUqVKYzQas/o2pCnTMTCPP/44P/74IwB//PEH4eHhqd3Hmjdvzvfff8+yZcuYOnUqFStW9Jni\nBeDcOQWNRqVoURkDI4QQQgghvIfJFEDp0mX59tt5NG3aPHW51ZpI4cIPkJCQwOHDh9IdAxMXF8eD\nDz6ERqNh+/atqeuVLFmKP/74HYCxY0dy9uzfaS4LCAggJsbTiHHs2JE0tx8aGorJZOLkyRNcvXoV\nh8NBhQqPcuiQZ3KvNWtW8sMPGwBo3Lgpn346/pbXkl2ZFjDVq1enYsWKtG/fnlGjRjFs2DBWrVrF\n5s2bM3uq1zt3TkORIioGGf4ihBBCCCG8TNOmzTlwYB8NGjRMXfbSS23o1as7EyaM5tVXu7Bw4fzU\nQuPfnnyyMbt376Rfv174+/sTHh7OvHmz6NfvA6ZO/YxevbpjNgdRsmSp1GUdOnRIXday5UtMnjyB\nAQP6UahQ2G3bL1v2Efz9TfTq1Y2fftrEiy++xOTJ42nTpgO//36Uvn17sHv3Lho1egqAJk2acv36\ndWrUqJXj90VR/z2o5S7Ij36ZafUHTU6GEiXMPPGEk5Urk+96TMI3SF9ikV2SOyInJH9EdknuiJzI\ny/z57rt1XL16he7de2Y5lvTc8SD+e0VsrKdf38MPy/gXIYQQQggh8sr48aO4fPkSY8dOypXt3bcF\nzIMPqkyfnky9ejL7mBBCCCGEEHll4MCPc3V7920Boyjw8svOzFcUQgghhBBCeI1MB/ELIYQQQggh\nhLeQAkYIIYQQQgjhM6SAEUIIIYQQQvgMKWCEEEIIIYQQPkMKGCGEEEIIIYTPkAJGCCGEEEII4TOk\ngBFCCCGEEEL4DEVVVTW/gxBCCCGEEEKIrJAWGCGEEEIIIYTPkAJGCCGEEEII4TOkgBFCCCGEEEL4\nDClghBBCCCGEED5DChghhBBCCCGEz5ACRgghhBBCCOEzdPkdQF4aM2YMR44cQVEUBg8eTOXKlfM7\nJOHlJkyYwKFDh3A6nfTs2ZNKlSoRERGBy+UiLCyMiRMnYjAY8jtM4aVSUlJ4/vnn6d27N/Xq1ZPc\nEVm2bt06Zs+ejU6n45133qFcuXKSPyJTVquVgQMHEh8fj8PhoE+fPoSFhTF8+HAAypUrx4gRI/I3\nSOF1Tp06Re/evXnttdfo1KkTV65cSfN4s27dOr755hs0Gg1t27alTZs2+R16qnu2BWb//v2cO3eO\nyMhIRo8ezejRo/M7JOHl9u7dy59//klkZCSzZ89mzJgxfPHFF3Ts2JHFixdTokQJVqxYkd9hCi82\nffp0goODASR3RJbFxsYybdo0Fi9ezIwZM/jpp58kf0SWrF69mlKlSrFgwQKmTJmSer4zePBgli5d\nSmJiItu3b8/vMIUXSUpK4pNPPqFevXqpy9I63iQlJTFt2jTmz5/PggUL+Oabb4iLi8vHyG91zxYw\ne/bs4emnnwagdOnSxMfHk5iYmM9RCW9Wq1YtpkyZAkBQUBDJycns27ePJk2aAPDUU0+xZ8+e/AxR\neLEzZ85w+vRpnnzySQDJHZFle/bsoV69egQGBhIeHs4nn3wi+SOyJDQ0NPWk0mKxEBISwqVLl1J7\nnEjuiP8yGAzMmjWL8PDw1GVpHW+OHDlCpUqVMJvN+Pn5Ub16dQ4fPpxfYd/mni1goqOjCQ0NTf27\nQIECREVF5WNEwttptVpMJhMAK1asoGHDhiQnJ6d22yhYsKDkkEjX+PHj+fDDD1P/ltwRWXXx4kVS\nUlJ466236NixI3v27JH8EVny3HPPcfnyZZo2bUqnTp2IiIggKCgo9XHJHfFfOp0OPz+/W5aldbyJ\njo6mQIECqet423n0PT0G5t9UVc3vEISP2LJlCytWrGDu3Lk0a9YsdbnkkEjPmjVrqFq1KsWKFUvz\ncckdkZm4uDimTp3K5cuX6dKlyy05I/kj0rN27Voeeugh5syZw4kTJ+jTpw9mszn1cckdcafSyxlv\ny6V7toAJDw8nOjo69e/r168TFhaWjxEJX7Bz505mzJjB7NmzMZvNmEwmUlJS8PPz49q1a7c0uQrx\n/7Zt28aFCxfYtm0bV69exWAwSO6ILCtYsCDVqlVDp9NRvHhxAgIC0Gq1kj8iU4cPH6ZBgwYAlC9f\nHpvNhtPpTH1cckdkRVrfV2mdR1etWjUfo7zVPduF7PHHH+fHH38E4I8//iA8PJzAwMB8jkp4s4SE\nBCZMmMDMmTMJCQkBoH79+ql5tGnTJp544on8DFF4qc8//5yVK1eybNky2rRpQ+/evSV3RJY1aNCA\nvXv34na7iY2NJSkpSfJHZEmJEiU4cuQIAJcuXSIgIIDSpUtz8OBBQHJHZE1ax5sqVapw7NgxLBYL\nVquVw4cPU7NmzXyO9B+K6m1tQrlo0qRJHDx4EEVRGDZsGOXLl8/vkIQXi4yM5Msvv6RUqVKpy8aN\nG8fHH3+MzWbjoYceYuzYsej1+nyMUni7L7/8kiJFitCgQQMGDhwouSOyZOnSpakzjfXq1YtKlSpJ\n/ohMWa1WBg8eTExMDE6nk379+hEWFsbQoUNxu91UqVKFQYMG5XeYwov8/vvvjB8/nkuXLqHT6Shc\nuDCTJk3iww8/vO14s3HjRubMmYOiKHTq1ImWLVvmd/ip7ukCRgghhBBCCHFvuWe7kAkhhBBCCCHu\nPVLACCGEEEIIIXyGFDBCCCGEEEIInyEFjBBCCCGEEMJnSAEjhBBCCCGE8BlSwAghhBBCCCF8hhQw\nQgghhBBCCJ8hBYwQQgghhBDCZ0gBI4QQQgghhPAZUsAIIYQQQgghfIYUMEIIIYQQQgifIQWMEEII\nIYQQwmdIASOEEEIIIYTwGVLACCGEEEIIIXyGFDBCCCGEEEIInyEFjBBCCCGEEMJnSAEjhBBCCCGE\n8BlSwAghhBBCCCF8hhQwQgghhBBCCJ8hBYwQQgghhBDCZ0gBI4QQQgghhPAZUsAIIYQQQgghfIYU\nMEIIIYQQQgifobvbO4yKSrjbuyQ01ERsbNJd36/wfZI7Irskd0ROSP6I7JLcETnhTfkTFmZO97H7\nogVGp9PmdwjCR0nuiOyS3BE5IfkjsktyR+SEr+TPfVHACCGEEEIIIe4NUsAIIYQQQgghfIYUMEII\nIYQQQgifIQWMEEIIIYQQwmdIASOEEEIIIYTwGVLACCGEEEIIIXyGFDBCCCGEEPcxJS4Wc9+eGDb9\nkN+hCJElUsDcdOXKZbp375zfYQghhBBC3DWKJZ7gdq3xW7YE/6lT8jscIbJEChghhBBCiPuQkmAh\nuN1L6H89jKoo6H87DHZ7foclRKZ0+R2ANztz5jSffjoeRVEwmQL4+OPhaDRahg79ELvdjsPh4L33\nBlKkSNHblpUrVz6/wxdCCCGESFtiIsEdXkF/6AApr7RDDQjE/5s56I7+hrNm7fyOTogMSQGTgSlT\nJtG7dz8qVnyMxYsXsHz5UsqUKUtYWDiDBg3l0qWLXLhwnqtXL9+2TAghhBDCK1mtBHdqi37/XlJa\nv0zCF9Mxrl2F/zdz0O/fJwWM8HpeV8AMH25k/frcDatdO4iIuPPnnT37NxUrPgZA9eo1mTfva158\n8WVmzZrOxIljaNSoMXXr1ic6Ovq2ZUIIIYQQXicpieAu7THs3oXthVYkTJsFOh2O2nUB0O/fS3Lv\nt/M5SGH44Tt0R38jqf8HYDTmdzheR8bAZJHT6UCj0VCoUCHmz19Co0aNWb16BfPmzUpzmRBCCOFV\nVDW/IxD5LSWF4K4dMOzcjq3F81hmzAGd56Kxu2gxXA8+hH7/HsmV/OR2Yxo3iuCuHQiYPJ7grh0g\nOTm/o/I6XtgCY2P4cFuubjMszExU1J0/r1Sp0vz++1Eee6wyv/56mHLlKnDgwD6cTif16j1OyZKl\nmDx5XJrLhBBCCG9hXLaEwI8GktL5NazvD4SAgPwOSdwplwvDjz/gP2s6+l8P43roIdzFS+AqVgJX\n8RK4ixfHVaw4VCyL9lIUSmKi5ychASUxASUxEeP6tRh2/IytWXMss+aDXv/P9hUFR526+K1Zhfbv\nM7geLpNvL/W+ZbUS9PZbGDesxVW8JK6SpTBs3UJwx1ewLFiKGmjO7wi9htcVMPnp/Plz9O3bI/Xv\nN954i5kzp6EoCmazmcGDh2GxWBg5cgiLFn2DRqOhe/eehIcXvm2ZEEII36c5fw7dsaPYWzwHGt/s\ntKDbvw/ze2+j2O2Ypn6Occ1KEsdMxN782fwOTWSBEh+H3+KF+M/5Gu35swA4HymHJjoK3ek/03xO\ngQy2Z2vSFMucBWAw3PaYo7angNHt3ycFzF2muXyJoC4d0B/9DXu9x7HMXYhqNhP0VneMG9YS3KYV\n8UtXogaH5HeoXkFR1bvbThgVlXA3dwf8fwvM3d+v8H2SOyK7JHd8n3HtKgLffRtNYgK25s+RMHUG\nalDwXdl3buWP5tJFQps9iXIjBsu8RegOH8Q0bQqKw4Gt+bMkjp6Au1jxXIhY3JGkJPxWLUeJiUYN\nC8cdFoY7LNzzUygMjEa0Z/7Ef9YM/JYuRkmyovr7k9KmA8lvvoXr5kynSoIFzYULaM+fQ3vhHJrz\n5zHFx5Cs0aMGBqIGmj0/ZjNqYCDu0AI4nmh0a8vLv+iO/kbo0w1J7tSVxE+/vJvvyH1Nd/ggQV06\noL1+jeRXu5A4/tN/CkynE/M7vfBbEYmjUhXil61BLVgwz2Lxpu+usLD0W5ykgBEiA5I7Irskd3xY\nSgqBwwbjP282qikAZ/ny6A8fwlm6DJb5i1NPHvNSruSP1UpIy+bojx0hcfR4kt/sBYD25AkCI97F\nsOcXVJMJ6weDSO7ZO92TWpF7FEs8fvNmY5o5DU10dLrruYND0MTHAeB6qAjJ3XqQ0rkramhGbSse\nOcodp5NCZYrhKlqU2F0HsrcNH6U7+huG79eT0qUb7oeK3LX9Glctx9y/D9jtWEeMJrlHb1CUW1dy\nuwkc0B//BfNxlitP/Ip1uAs/kCfxeNN3V44LmAkTJnDo0CGcTic9e/akWbNmqY81btyYBx54AK1W\nC8CkSZMoXLhwutuSAkb4EskdkV2SO75J8/dfBL35Gvqjv+Gs8CiW2d/iKvUwAaNHYJo2BdUUgOWL\nr7C3bJ3hdpQbMeh/2YXjyadQzUF3HEeO80dVMb/5Gn7rVnuupk/+4taTIlXFGLmYwBEfo4mJwVnh\nUZK7vI6j7uO4Kjzqs93l7jq7Hf3B/bjDwnGVejh1QPx/KdHR+M/6Cv85s9BY4nEHBZPc/U2cNWuj\nREejibr+r58oNNev4S4URspr3bE9+8IdFZc5zZ3gV17EsONnok/8jVog7670exPD+jUE9emBkpKC\n6u9PUp9+JPXpl6djxTQXL+D/1ReYZs/EbQ4i4eu52Js0S/8JqkrAkA8xfT0dZ6mHiV+5HnfRYrke\nlzd9d2VUwGQ6Bmbv3r38+eefREZGEhsbS+vWrW8pYABmzZpFgAwIFEII4cMM61ZjfvdtNAkWTzeO\n0RPAZALAOuwTHNWqE/ROb4Lf6EpS70NYPx5+6wmrzYZh00b8li/F8NMmFIcD56OPER+5Ks+ulqbH\n9OkE/Natxl63PonjJt9+RVdRsLV/FXuz5gSMHoH/gvmYBw0AwB0SgqNOPRx1H8dRrz7OSlWkdeY/\nlJgY/L+Zg9/cWWivXwNANRhwlS6Ls3x5XOUfxVmuAu6iRTEuX4r/gvkoSUm4CxUi8ePhpLzW/a51\nR7xTjtp1MOz4Gf2B/difaZHf4eQtVcX/y88JHDUMd0AgSe8NwG/htwRMGoffom+xfjQM2yvtcq+g\nV1X0+/bgP2sGhu/Xo7hcuEqWIn5BZOYtu4qC9ZNxqAEBBHw2iZCWzYn/dimuxyrlTmw+JtMWGJfL\nhc1mw2Qy4XK5qF+/Prt3705tcWncuDHr16/PcgEjLTDCl0juiOxQEiwU2ryB6AZPo4aH53c4IjM2\nm6fL2NxZqCYTCRM+w9a2Q5qrak+eIOi1jujOnMbeoCGWmfPQnjmN3/KlGNetTu3246xQEVeJkhg3\nfoereEnilq3G/XDpLIeU5rEnKQnTl5+h/es09ubPYWvWIs0rxIYN6wju1glXseLE/rgNtVChTPen\nOfs3ht270O/5Bf2e3amDxQFUUwDJnbti/XjEfX8/Cu2J4/h//RV+KyJRUlJwm4OwvdwGJSUF7cnj\n6E6eREmy3vY8V5GiJPV5h5SOXVKL4ryS0+8t/bathLRtRdLb72IdMiIXI/MyDgeBEe/iv+hbXA8V\nIX7hMlyPVUJJTMD/y88wffUlis2Go1p1EkeOw1mn7j/PdbnQXDiP9q/T6E7/ieb8OdTQArhKPYzr\n4dK4Sj1862B7mw3j6hX4z5qB/tgRz+4fq0xyj17YWr0Mfn53FLr/lMkEjh6B6ufnOV61fzU33hHA\nu857cm0MTGRkJAcPHmTixImpyxo3bkz16tW5dOkSNWrU4P3330f575Wef5ECRvgSyR1xx1SVoM7t\nMG7aiDvQTFL/Zt+mOQAAIABJREFUD0ju0euOv6BE2pToaNTg4DtvEVBVNNeuov3rzD8/f//l+ffs\nXyjJyTjLV/B0GXukXMYxWOIxv90L4w8bUHU6FKcTAFfhB7C93JaUNu1xVXwMVBXTpHEETByLu1AY\n8UtX4qxcNUvh/vfYo9+6BXPEe7cWFv7+2Jq1wNbqZexNmoKfH9rfjxH6fFNAIXbDpmxfndVcuoh+\n7270e3Zj2LoZ7cULOCpXxfL1vDsqxO4Jqoph62b8Z0zDsP1nAFwlSpLcoxcpHTrdOrWt243m4gV0\nJ4+jPX4c7dm/cNasTcor7dKc9Ssv5PR7S0lMoGCZYjhr1SFu/Y+5GJn3UOJiCereBcPO7Z68XhiJ\n+4EHb1lHc+E8AaOG4bd6JQC2Zs1Bq0N75k+0Z/9Gsdsz3Ie7QAFcpUrjKlYMw66daKKjUDUa7M++\nQHKPXjjq1Lu9ZfQOGDZ+j7lvTzSWeE830dETwN8/29v7f9503pNRAYOaRZs3b1ZfeeUV1WKx3LJ8\n9erVanR0tOpwONQePXqoP/zwQ4bbcTicWd2lEEL4nkmTVBVUtWpVVS1UyPN7qVKqumKFqrrd+R2d\n73I4VLV/f8/7GRCgqs88o6rjxqnqvn2ex/7LalXVbdtUdfRoVX32WVUNDfU8978/gYGqWq2aqr73\nnuc5WeVyqeqYMar6wAOq2rmzqm7apKrOdL7fvvpKVRVFVc1mVd269c5e97VrqtqxoydWrVZVIyJU\n9fBhVR0yRFXLlv3ndZjNqtqli6qWKOH5e9WqO9tPRqxWVe3W7Z/9REbm3ra9ndutqm+88c/7/OST\nqrpmTfqf9b2ialVVNRpVNSUlvyPJfWfOqGr58p7P88UXVTUxMeP1f/lFVWvX/icHgoJUtVYtVe3U\nSVVHjlTVpUtVdf9+Vd24UVW//FJV+/VT1eeeU9VHHlFVnc7znNBQz//ds2dz/7VUq+bZR7Vqnr/v\nE1lqgdm5cydTpkxh9uzZhISkP//0okWLiImJ4Z133kl3HW9sgenZ83XefTeC8uUrpC6bMWMqwcEh\ndOjQ6bb1Dx8+yKpVyxg1akKGy4Tv86YrEcL76Q7sI+TFFrgLFER79AjRCXZMn07Ef/YMFIcDe73H\nsY4a5xlTILJMscRj7tkN40+bcZUshWowoDt1MvVxtzkIR916OOrURxN1Df3+veiOHU1tGQHPFXNn\npSqe7h03f5ylSnu6+OXgKmhWGdatJqjXG6AoWKbPwf7CixmuH1YokIQvphMw/CM0cXE4qlUnYdIX\nuCpV/mclVUX3+1GMq1diXLMS7cULAFgHfkTS+wNz/TUYly/FPOBdlCQryV27k/jJ2LvesqjciMF/\n7ixwuTxTDocXvvmvZwpiAgNzb2eqSsCwjzDNmIqjclUSP/vSJ/7v5sb3VuCgD/Cf8zWx323GWatO\nLkWWz9xuDFt+xNyvN5qYGJJ6vY116Ei4OSQis+dqT57AXSjM0yUzq8cMpxPNlcueqbFzoXUkTSkp\nBH4Ugf+C+biDgkmYOjNH93jypvOeHA3iT0hIYMKECcyfP/+24iUhIYH+/fszffp0DAYDBw4c4Jln\nnsl5xHdZ06bPsHXr5lsKmG3btvLllzPyMSohhC9RYm8Q1LMbuN0kzJhDSOHCqJoErCNGk9L1dQKG\nD8G48Tv0TzckpUMnkt6LwF28RH6H7fU0Z/8muHM7dCdPYGvSlISv56Gag1CuXcOweyf6XTvQ79qB\ncfOPGDd7uruoej3OKlVx1KqLo3ZdnLVq3/VB9P9lb9ma+OAQgl57laA3upA44TNSunbzPOh2oyRZ\nPXdMt1jQREfBlImYt23DHRDomQK5W4/bT7QUBWelKjgrVcE6ZAS6g/vRXrqI7cWX8uQ12Nq0x1m1\nOkFvdMX/mznoD+7HMns+rtJl82R/t1BVjGtWEvhRRIbTD6umABzVqmNr2Rrbcy1zNAbN9NlETDOm\n4nykHPGRq/P03hvexlG7Lv5zvka/b6/PFzBKfBx+SxfhN3cWur//QtVqSZj4+T///7JCo/HMznen\ndLq8v8+Snx+Jk7/AUasO5oHvEdylPUl9+2MdPDTdWfHuBZm+su+//57Y2Fj69++fuqxOnTqUK1eO\npk2b0rBhQ9q1a4fRaOTRRx+lefPmeRpwXmjSpBm9enWnd29Py9GJE8cJCwsjLCycAwf2MXv2DPR6\nPWazmZEjx2W6vZ9+2kxk5CK0Wi3lylWgf/8POHXqBJMnj0ev12MwGBgxYixXrly6bZnZnEF/PyGE\nd1JVzO/0QnvxAtaIwTgaNLzlYdfDZbB8uwT9jm0EDhmE/+IF+C1ZiP2ZFiR364Gj4ZP31LS1SlQU\nfksWgKqS0rUbakhotraj37uboNdf9Vwt7dkb6/DRqSfxauHC2Fq/gq31K4DnLtb6A/twF34AR5Vq\neXe1MwccjZ4ifvUGgju+gnlAf0yfTURJTERJsKCk0RnC1vxZEsdOwl2kaOYbVxScterk+cmmq+wj\nxG7c6snjb+cS8nQjEj/70jMQOY9oLl0kcOB7GDdtRPX3J3HISJzVqnumHL5+Dc316//8fuUyhl92\nYvhlJ4GDPsDx+BP/FDNZmMzg//nNnkHAuFG4ipcgfvna+6p4AU8BA6Dfv5dk+uVzNNmj/eN3/OfO\nwm9lJEpSEqrRSEq7jiT16H1rS+Y9wtb+VZyVqxLUrROmqZ+jO3oEy6x5Wbp3kC+SG1ne9N57fXnj\njbd49NHH+OqrLyhatBgtW7Zm69YtlC9fgYceKsInnwzlqaeexmQypduFbPDg4bz+ekfmzVuMyWQi\nIuJd2rd/lR07fqZ8+Udp3vw5Dh06QKFCYaxevfy2ZSVKlMzjd0PcCW9qShXey3/6VAKHDcb+xJPE\nL1sNWm36ueNyYVy1HP85M9EfPgSAs0xZUl5/g5R2Hb12atWs0P7vD88MTSuXodhsAJ77XfTqS3KP\nXnd0PxTj0kWY338HVJXEcZNJ6fJ6XoV912nP/Im5Tw80UVGo5iBUsxl3kOdf1RyMajZjav40UbWe\nuCvd27LLuHoFge/3Q5OYQOJHw0h+573cjdftxm/+HAJGDUeTmID9iUYkTJqCu9TDGT5Nc/kSxvVr\nMK5djf7gfgBUrRbH4w1JeaWtp4UqgwLXGLmYoLffwhVemLh1G31u0oLc+t4qUO1RFFsKMX+c8eo8\n/C/Dlh/x/+IzDHt3A+AqVpzkrt1JebXLfVGIKgkWzH16YNz4Pc5SD2NZEJnpxCT/5k3nPTnqQna3\nBQz/GOP6Nbm70XZtIWJohqs0bdqcn37azKOPPsYvv+xg+vS5AISEhDB+/ChcLheXL1+iRo1amDKY\nAvHChfMULVo8dZ1q1Wpw6tQJGjRoxKRJ47hw4TxNmjSlRImSaS4TQvgW3aEDBHwyFFd4YSzTZ2fe\nn1qrxdamPbY27dEdPoj/3Fk3u8YMJGD0SFLatifprb6+c9LkdmP4aRP+M77CsHMbAM5SD5PcoxdK\nig3Tl58SMH40/rOmk9T3XZK7vZnxNLJWKwGTxmGaNgV3SAiWuQtva9Hyda7SZYnb+HOG65jCzOAl\nJxHpsbV+BeejjxHc/iUCR49Ae+kiiWMnZW1MQSa0p05ifrevp1UtOATLlK88U8Vm4UTa/VARknv2\nIblnHzSXLqYWM4YdP2PY8TPuYYNJ6diF5Ne64/7P967h+w2Y+/fBHRJC/LI1vvP/MA846tTFb9UK\ntH+dvjvdBHMqJYXA4R95xkgB9icbk9ytB/amz+RKTvoK1RyEZf5iTONHee4X07wxCTNmY292b93T\n597ps5BDjRo9xe7dOzlx4n8UK1acoCDPlcKxYz/h3XcjmDr1axpk4UtUUeDfjVpOpwONRkPNmrWZ\nPftbSpQoyahRwzl8+GCay8Q94OZ0reLep8TeIKjH6+BykTB99h33t3dWr0nC1JnE/HaCxI+G4Q4N\nxX/+HAo0qEXAkA9R4mLzKPJcoKr4LV5A6OM1CX61LYad27A/0Yj4BZHE7jlMSveeJPd5hxsHj2H9\n8GNwuggcOYSCtSrjN3sGSoIF7e/HMK6IJGD0CII6t6NAzcqElXoQ07QpOEuXIW7j1nuueLnXuMqV\nJ+6Hn3BWrIT//DkEvf4qJCVle3tKXCwBwz8mtPHj6A/sI6Vla27sOoCtQ6dstQK4ixQl+a2+xP3w\nEzEHj2F99wPQajFNm0KB2lUI6tQW/dbN4Haj37GNoB6vgdGP+MUrcD1aMduv417gqOXpRqbbvy+f\nI8mc5q8zhDzXFP+5s3CWr8CNn3cTv2yNZzD7fVS8pNJoSBo0FMvMuShOB0Gd2+P/xWeeedTSoFy7\nht+cmQS/8iJ8/vldDjZ7vK4Fxjp8FNbho3J1m2FZuJJlMgVQunRZvv12Hk2b/jOOx2pNpHDhB0hI\nSODw4UOUzuQqRLFiJbh48TxJSVZMpgB+/fUwXbt2Z+XKSOrVa0CzZi1QVZVTp07w999nbltWvXrN\nXHnNIv+Yxn5CwOeTSO72JonDR8v9P+5Vqoq5X2+0F85jHTAIxxONsr+pQoVI7vc+yX36YdywloBR\nIzDN/Aq/ZUuwRgwmpUs377oTus2GeUB//JYuQjUYSO7QieQ3e6V5zxE10EzSexEkd3sT/+lfYpo5\nHfPgCMyDI25b110oDHuDhjirVCOp33vZHjsj7i73Aw8St+4Hgl7vjHHj94S8/DzxC5bd0ZgT7Hb8\n583C9OkENLGxuIoWI3H0BOwtnsu9OIuXIGnQUJLeG4hx3WpP6+emjRg3bcRZ6mG0164BEP/tEpw1\na+fafn1V6jiYfXs8BaSXMq5dReC7b6NJTCC5Y2cSx0zM85uF+gpb61dwPVyaoC4dCBw1DN3/fifh\ns6ng749yIwbjd+sxrlmJ/pedKG43qqJAsyb5HXaWyBiYf9m+/WdGjRrGhg2bMBo9J52zZ89g164d\nFCtWnPr1GzB37tf06NGb7du3pjuN8vbtW1m6dCGKoqFy5aq89VZf9u7dzaxZ0wkMDESv1zN48DBO\nnTp527ICBe79/pm+5E77gmquXKZA7Sqp/f+djz6G5et5d9T/VPgAVcU0cSwBk8Z5Wh2WrbntKl+O\n+hHbbPjPmoHps4loEiw4yz6CdcRo7E2a5XtfdCU6muDXX0W/bw+OqtWwzFuUtUHm/3q+aern6I78\niqt0WZwVKuAqVwFnuQqoYWF5GLlv8aZ+6Flmt2N+ty9+y5fiLPUw8UtXZTpeBVXFsH4NgZ8MQ3vu\nLO6gYM/NX9/oeVcu/uh+O+wpZFavAKcTy5wF2J99Ps/3m5dyLXdcLgqWLY77gQeI3X0o59vLbSkp\nBA4dhP/8OaimABImfoatTfv8jsorKdeuEfxaR/SHDuCoUg13oUIYtv+cOtW8o2ZtbK1fxvZCKwpW\nesRrjj0ZjYGRAkaIDNxp7gQOeBf/b+aQMHYiuhMn8P9mDqrJROLoCaR07JzvJ59eITkZxW5DDU7/\nnlJ3k/av07iDQ7M+uFNVCRg5FNO0KbiKFSfu+y1pTtGbG8cdJSqKgAlj8FswD8Xtxv5kY6wfDfPc\nzT0fckl7/H8Ed26H9vw5Ul58iYQpX8mVzjzis99bqkrAmJGYpkzGXagQlmmzcJUo6WlBNBhQ9XrQ\n61H1BnRHfiNw+EfoDx1A1elI7vYmSe9FoObDhTzlRgxKXNw9MeYlN3MnuG0rDNu2En38b68aAK89\n8yfmN19H//tRnBUqYpn9Da6yj+R3WN7tXy3nAI4q1bC9+BK2F1vfMtWzNx17pIDxog9D+JY7yR3N\n2b8pUL8GruIliN11AHQ6DOvXYn7vbTTxcaS0eonESVN8epapHHG78Vu8gIDRw0FRiN2yE/dDRfIl\nFM3Zv/FbvQLjmpXojv/Pc/Vu7MTMBwm7XARGvIf/gnk4y5QlfvnadFsfcvO4o/3fHwQOG4xhu2fg\nt7N8BVJebovtpTZ5f4+BmwybN2Lu0Q2NNRHrgEEkffChFOR5yNe/t/zmzSZw0Acobnem69peaOUZ\nA3YPFA/eIDdzxzRpHAETxhD/7dIc3Rwx21QVzdUr6I4dQXfsqOfn96Noz58DILnzaySOGu+V06Z7\nJVVFv2Mb7mLFcD1cJs1VvOnYIwWMF30YwrfcSe6Y+/TAb/lSLDPnpt6bAkBz4TxBvd5Av38vruIl\nsMyYc9/1r9YdOkDgoA/Q//Yrql7vuSt93frEr9pw1260pbl6BePaVRhXr0idvlg1GLA3egr93j1o\nEiyktGxN4sTP0p433+HA3LcHfqtX4qhUxXNjuwz6+Of6cUdV0f/8E/4L5mPYvBHFbgfAXrc+tpfb\nYmvZKm/m+1dV/GdMI2D4R2A0kvDF9Dy954fwuBe+t/Q7tmHcsBYcDk++Oh0odgc47CgOB2pAIElv\n9cVZ27dvlOhtcjN39Du2EfJKS8+NEYeOzJVtZiglBf1vh9Hv+QX93t3ojh257cal7oIFcT5WmZRO\nXfPspq33M2869kgB40UfhvAtWc0d7YnjhDaqi6tCRWK37rr9poROJ6ZJ4zB9NhE0GuIXr8DxlG8M\nlMsJ5fp1AkcNS22yTnmpDdahIwn8+EOMG9ZifX8gSQM/yvoGVfXOrvonJmLcsBa/5UvR79qBoqqo\nGg2Ohk+S0voV7M8+jxocgub8OYL69EC/bw+uh4qQMHXmrbNfJScT9EYXjJt/xFG7LvGLlmXaBS4v\njztKfBzGDeswrlzmGXypqqh6PfYmTT03d2zWAgIC7nzDNtttNwfU79qO3+qVuAo/gOXbJTir1cj9\nFyRuI99bIrtyNXcSEylUthjO6jWJ+25z7mzz36xW9Af3pxYs+kMHUseQAriKl8D5WGWclW7+PFYZ\n94MPSetvHvKmY48UMF70YQjfktXcCXq9E8bv1hG/MDLDudb1O7YR3LYVrjJlid225661PqTLasWw\n/WfPPPm5OcuVw4H/nJmYJo7zDEKvWInEsRNx1K0PeE7AQxs3QHPxAvEr12c+Va6qYpowBtNXX+As\nXRZHo6ewN3zSs73/dh1wudDv2oHfsiUYv1uHcnNKV0etOqS81AZby9ZpDxZ3uTBNmYxp4lhwu0nu\n2x/rwI9QbCkEdWqHYc8v2J9qQvy8RVka93G3jjuay5cwrlqB38pl6P44BoBqCsDWvAW2Vq9gf6oJ\nGI23PsnhQHf8D3QHD6A/dMBzlfPqFTRxcWnuw1G5KpYFSz0nDuKukO8tkV25nTshTzdEd+J/RJ++\nmKsTK/jNnUXgsMGpBYuqKDgrVsJRrz6Oeg1w1K1/ZzPZiVzhTcceKWC86MMQPsLt9gxE1apEvf8R\nGAzprqr79RChzzyFo0Yt4r7fkumVocD3++G/YB4Jk6bk+93Fzb3ewG/lMmzNn8Xy9fzsfzm53WhP\nHEe/b4/nZ/cutFev4A4JwfrhEM/r/E+xpju4n5CWzXEXLETsz7vT/6JyuQgc+D7+387FXaAASmJi\navcp1WjEUbse9kZP4axWHcOObRiXL0V7+ZLnqSVKktK2Aylt2uMuWSpLL0V36ABBvd5Ae/ZvHDcH\ny+uP/IrthVaeG1VmkAv/lh/HHe3JExhXL/fcfO7s3wC4g0OwPd8SR9366E4cR3foAPojv6IkJ6c+\nz20Owl2kCO6wwrjDw3GHF8YdFu75vfADnkLxv0WQyFPyvSWyK7dzJ+CjCEyzZhC7fhPOOnVzvkFV\n9YytmTgWd6FCpLR71VO01KnnNZO73M+86dgjBYwXfRjCB6iq54A9eyYA9icaYZm3MN3B9/8/S0vc\nqg1Zuume5tpVCtSphjswkBt7f4XAwNyMPst0hw8S2rwxqlaL4nJhf+JJ4r9ZnOV4dL8dRr/9Z0/B\nsn8fGkt86mPuggWxtWyNNeKjDGeu8f/ycwI/GYqtSVMsi5bf3vXOZvOMLVq3GmfFSsRFrkYNDES/\nbw+G7T9j2P5zaqtD6r7NQdhebE1K246eL9tsdDVQEhMI+Ggg/ksWApDcoROJk7+4oxazfD3uqCq6\nI79iXLUC49pVaK9c/uchjQZXhYo4atTCUbMWzhq1cJUuc/t7L/KVfG+J7Mrt3DGuXUXQm6+ROGQk\nyW/3z9nG3G4CP4rAf87XuIqXIG7ZGpm8wct407FHChgv+jDuFdqTJ3CVKXtP3uHWNH40AZPH46zw\nKLpHysLatTgrVCR+yYrbZs3S795FSKtnPSf/K9dlfR8TxhAwaRzWiMGe2ZzuNlUl5IVn0O/fS9yy\nNZ77IGz8DketOsQvXp7hVTAlJobAIR/ityIydZmz1MM469TDUacejrr1PLObZKVwcLsJ7vAyhp9/\nInHYKJL7vPPPY4mJBL/+qqeLW936WBZGpllEKtevY9i1Hd2vh3BWr4mt+XO5NiON4ccf0Fy6SMpr\n3e/4BN9rjjtuN/p9e9AdO+LpnlGlWr4VzSLrvCZ/hM/J7dzRXLlMwSrlcdSqQ1zk6uwfP+x2zO+8\nhd+qFTgrPEp85GrcDzyYa3GK3OFNxx4pYLzow7gX6HftIOSl5+98ALYP8J85jcAhg3CVLEXc+h8p\nWOFhknv0wn/uLFwPPkT8kpW4Hq3oWflfRUDsDz/hrFEry/tREhMoUKcaitVKzL7fUAsXzqNXlDbD\n+jUEd++C7bmWWOYt9Myw9fZb+K1anv4MW6rquePx4AFooqNxVK1G0tvv4qhdL0fxK1FRhD5VH82N\nGOI2bMJZvSbKjRiCX22D/tBBbM+08HRv87FpMuW4I3JC8kdkV17kTnDL5hj27sZVpCiJ4yZjfyb9\nsZ5psloJ7t4Zw9Ytngtli5ahhoTmaowid3jTsSejAkb6DIg75rdwPgD+82bBv/rR+zrj0kWe4qXw\nA8QtX+u5OaFWS+LYSSQO/QTtlcuegmXndgAMWzej378XW/Pn7qh4AVADzVgHDEJJshIwaVxevJz0\n2WwEjhiKqteTOGSEZ5leT8K0r0nu/Br6Y0cIadUCzdUrqU/RXL1CUNcOBPV4HSUxkcTho4n7/ifs\nL7TKcfGlhoWR8NUscLkI6tEN7YnjhLRsjv7QQVLadsAyd6HPFS9CCHEviY9cjfXdD9Bcv0Zw53YE\ndet8y3dERpTYG4S0eRHD1i3YmjQlbtkaKV5EjkkBI+6IYonH+P0GADQ3bmBcszKfI8odhu/WY+7f\nB3doqOfmhCVK/vOgopDctx+WGXNQbCkEt38J4/KlmMZ8gqooWD/8OFv7TOnUFWeZsvgtnI/2z1O5\n80KywH/2TLTnz5LcveetfY+1WhInTSHprb7oTp0k5IVn0Jw7i9/CbwhtUBvjxu+xP/4EN7btIbn3\n27k6g5qj4ZMkvfsB2vNnCX2yHrpTJ0nq2ZuEL6bn7uxoQggh7py/P0mDhhL70y4cteti3LCW0Po1\n8ZvzNbhct6+vqmguX0K/bSshrZ5Ff3A/KS+1wfLt0uxN8S7Ef0gXMnFH/BZ+g/m9t0nu0g2/Rd/g\nrFCRuJ92+vSc7PrtPxP8ahvQ6YlbtR5n9Zqpj/03d/S/7CSoa8fUAespL7UhYcacbO/b8MN3BHft\ngK35c1i+XZLt7ShxseB2oxZIf8A8gBIdTYE6VUGn5ca+39K+CqaqmCaOJWDSOFSDAcVux20Owjp8\nFCmvdsm7wd5OJ8EvPY9h726sg4eS1O99n84rOe6InJD8EdmV57njduO36FsCRg5FEx+Ho0ZNkrv3\nRHvxAtpTJ9GePoX2zz/RWBNTn5LcvQeJoyfIZCE+wJuOPRl1Icvnm1AIX2Nc5jnJTur3HprYGxjX\nr0G/b0/q/T1ySrHEo7lwAe3FC2gunkd78SKaixfQXjyPJioa+P96+18ntsrN6XQffwJbi+dxPP5E\nlq/a6w4dILhrRwDiv11yS/GSFsfjTxC3YRPBHV5GEx2FNWJwNl7lP+zNn8VRpx7Gjd+h37v7jt9H\nzV9nMM2Yit/SRah6AwlfTMf+3Avprh8waSyaBAuJo8en34SvKCRFDEYNCCRg5BBsz7QgccJneX8P\nEJ2O+KWr0J79+59xRkIIIbyLRkNK59ewNWtB4NAP8Vu9Ev2hg6kPq0YjrofLYC/7CK4yZXFWr4G9\naXOfviAlvI+0wIgs05z9m4K1q2Bv0JD4VRvQ791NSMvmpLRsTcLsb3K0bf3e3QSMHIr+4P40H1f1\netxh4Z6rN/9O2Zu/KxYLmkTPZ+wODsHe9BlsLZ7H3vjpf5qrbTZ0fxxD9+th9L8dRvfbYbSnToKi\nYJm7EPuzz9+23/RyR0mwoMTEZPneIhnRHdxP6LNP46hRk7jvf8rSQV53cD+maV9g+H49iqriKlYc\nTUw0SlISSb3fwfrx8Nu6eGlPnSS0UV1cJUsRu2Nfloo8JcGCag7K7ku7r8lxR+SE5I/IrrudO/pd\nO9D9fhRX6TI4yzyCu3iJe3KG0vuFNx17pAVG5Aq/m60vKW07AHimzH2sMsbv1mG9dBF3kaJ3vE3t\nqZMEjBqGceP3ANgbNMRVpiyuosVxFyuGq2gx3EWLeQbUZ9T07HSi37sbw/frMf7wHX4rIvFbEYnq\n54ejfgOUGzHo/vgdxeFIfYo7IBBHvcdJfrNXmsVLRlRzUK6d2Dtr1ialZWv81q3GsH4N9pat017R\n7cbw4w+Ypk1Bv38vAI4q1Uju8w62519E++cpgrp1wvTVF+h+PUTC1/M879tNASM+RnG5sA4bleUW\nKilehBBCZMTRoGGW7oEmRG6SFhiRNapKgVpV0ERfJ+b3P1EDPVWx3+IFmPv3Ianf+1g/GpblzWmu\nXsE0cSx+i75Fcbux162PdehInDVr50qsuqO/eYqZ7zegO3kC1WDAWfExnFWr46hWA2fV6rjKPpLp\nVaK7lTuav85QoEEt3EWLcWPrL2ivXEZ75jTav87c/Pc0ulMn0URdB8D2dDOS+/TDUb/BLS02SoIF\nc/++GNevwR0WjmXWfBz1G3gGUrZt5Wk9W7lemvLvAjnuiJyQ/BHZJbkjcsKb8kfuA+NFH4avSu0u\n1qY9CdNNcN64AAAgAElEQVS+/ueB5GQKVqsAQMyvxzOd7lZJsOA/bQqmGdNQkpJwPlIO65CR2Jvl\nXf9YzbWruENCwWi84+fezdwJGDwA0+yZaT6mKgruIkWxN3yS5Lf64ipfIf0NqSr+X39FwIghoKpY\nBw3Fb+UytCf+R9yWHTgrVcmjVyD+TY47Iickf0R2Se6InPCm/JEuZCLHjJGLAUhp1/HWB/z9Sen8\nOqYpkzGuWYmtQ6d0t6G5fImQli3Qnj+Lq/ADJI0aT0r7V3N1Ot60/LsblTdLev9D9EePoGo0uB4u\njevhMrhKl/H8XrJU1u+Foigk9+yDo2oNgt7sSuAoT8tYcodOUrwIIYQQwudJC4zIXFISBR8rixoc\nzI1Dv982FkVz6SIFalbKcEplJSqKkBebozv9J0m93vbM3uUDc8H7eu4o168T1OdNtCeOE7d5O+4H\nHszvkO4bvp47In9J/ojsktwROeFN+ZNRC4xMyC0yZdz4HZrEBFLatE9zIL27SFHsz76A/vej6Pbt\nve1xJS6WkLatPMVL3/5Yh4/yieLlXqCGhxO/fC03fjsuxYsQQggh7glSwIhM+d3sPma7OftYWpLf\nfAsA/9kzblmuJCYQ3OEVdH8cI/m17liHjJAB5PlBprQUQgghxD0iSwXMhAkTaNeuHS+//DKbNm26\n5bHdu3fzyiuv0K5dO6ZNm5YnQYr8o7l6Bf32n3HUqImrTNl01/v3lMqaSxc9C5OTCerSAf2hA6S0\naU/iuMlSvAghhBBCiBzJtIDZu3cvf/75J5GRkcyePZsxY8bc8vioUaP48ssvWbJkCb/88gunT5/O\ns2DF3WdcHonidpPStmPGKyoKKW/0RHG58J8/B+x2gt7ogmHXDmzPvkDClK8yvo+LEEIIIYQQWZDp\n9E+1atWicuXKAAQFBZGcnIzL5UKr1XLhwgWCg4N58EFP3/pGjRqxZ88eypQpk7dRi7tDVfFbthjV\nYMDW6qVMV09p/QoBI4fgt2Ae2r/OYNz8I/anmmCZOTfPZxoTQgghhBD3h0zPKrVaLSaTCYAVK1bQ\nsGFDtDf700dFRVGgQIHUdQsUKMCFCxcy3F5oqAmd7u73x89oJgORjkOH4OQJePllCj1SIgtPMEPP\nnjB2LMb1a+CJJzBsWEfYzfzxVZI7Irskd0ROSP6I7JLcETnhC/mT5cviW7ZsYcWKFcydOzdHO4yN\nTcrR87PDm6aE8yUBM2ZhAuJbtcWexfdP07YzoV9OxVWmDPHzFqNaXWD13fdeckdkl+SOyAnJH5Fd\nkjsiJ7wpf3J8I8udO3cyY8YMZs+ejdn8z8bCw8OJjo5O/fvatWuEh4fnIFThNex2/FavwF2oEPbG\nT2f5ae4iRbmx/whqaKjMfCWEEEIIIXJdpgVMQkICEyZMYP78+YSEhNzyWNGiRfm/9u49PIry7B/4\nd2Z2N5vsJiEhuwlnI3IIEE4ClgKpClF+wbfQ+ipIwVq1VaBSWyoqtYIF8VCqCFLkDSAtFgUBxf6k\n0kqhUgki0hcJB8NRSICQQM6bZHd25v3jYTcJ5Lyb7G7y/VzXXDObPd07e2f2ued5Zqa0tBTZ2dlI\nSEjArl27sGTJkhYLllpQZSWUE1kwHM2E4UgmDP/5CvKVK3A8NhMwGpv0UnpcXAsFSURERETtXYMF\nzPbt21FQUIAnn3zS+7fbbrsNffr0QWpqKhYsWIA5c+YAANLS0pCYmNhy0ZLfyGdOw7T7nzDu3wfD\n0UwoJ7IgqWqNx6g390TFQ48EJkAiIiIiolpIuq7rrfmGgRhXF0zj+QJFKiyAcc9nMP1rF0y7/wnl\n3FnvfXqEBWpSP6j9BkDtPwBqvwFw9+sHPSo6YPEGC+YONRdzh3zB/KHmYu6QL4Ipf3w+BoZCV9jm\njQhfswqG/xyEpGkAAC0qGpVp/wXn9+6Aa8z34L65J6/RQkREREQhgQVMW6XrCF/2GqwvvgBdUaAO\nGwHn7XfC+b07oA65lddlISIiIqKQxFZsW6TrsCx4DhErl8PdtRuK3v8Q7p69Ah0VEREREZHPWMC0\nNaoK669/gfAN66H26o2i97dB69wl0FEREREREflFuz3wwe0Gliwx4dixNrQKKioQ9eiPEb5hPVyD\nh6Dwox0sXoiIiIioTWlDrfemuXxZwquvhmHZMlOgQ/ELqbQE0T+6D2Hb/wrn6BQUbf3/0Dt2DHRY\nRERERER+1W4LmPh4HRERepvogZGuXkH0vf8F055/oXL8BBRt2AzdWvep54iIiIiIQlXot96bSZaB\nPn00nDghw+UKdDQ+UFVE3zcJxv8cRMWUH6F47XrAbA50VERERERELaLdFjAAkJTkhssl4fTp0F0N\n5o0bYDx8CBU/vA8lS1fw9MhERERE1KaFbsvdD5KSxIUdQ3YYWXk5In7/EnSzGWULFvFilERERETU\n5rXrFm+oFzDhb6+GciEH5T+dAS2hU6DDISIiIiJqcaHZcveTvn1Dt4CRiosQ8cYSaNEd4HjiyUCH\nQ0RERETUKkKv5e5HdruOuDgNR48qgQ6lycL/uAxyQQEcP/8F9A4xgQ6HiIiIiKhVtOsCBhDDyM6d\nk1FaGuhIGk+6fBkRb62A2x6P8kcfD3Q4RERERESthgXMteNgjh8PnVVhef1VSA4HHHOeBiyWQIdD\nRERERNRqQqfV3kKqCpjQGEYmnz0D85/fhvumRFRM+3GgwyEiIiIialUsYJLcAELnQH7Lq4shuVwo\ne+Y5wGgMdDhERERERK0qNFrtLUHXEb5iGQbIRwGERgGjHMlE2JZNUPsno3LSvYEOh4iIiIio1bXb\ny7ZLhQWwLHwe4V1Xo1+3/8WxY5HQdUCSAh1Z3Swv/Q6SrqPsufm8aCURERERtUvttoDRY2JR/vMn\nEbHsNSzp+iukXVmDy5clxMfrLfq+cvZ5yNnZkPMuQ76cCzkvF3JenlguKIC7W3eoAwZC7T8Aav9k\n6DYbAMCwLwNhf/8EzpGj4LwztUVjJCIiIiIKVu22gAGAsrnzYNr5D/y/I2txDybh2LGxiI93t9j7\nmdemI/KZOXXer0sSjPv3AVs2ef/mjk+Au/8AyOfPiZh/syC4u4mIiIiIiFpQuy5gYDKh+I/piB6b\ngtXqo1h/4ABwe4cWeSvp6hVYFv8OWnQHVPz4YWh2OzR7PDTbtbndDt0aCeXsaShHMmE4chiGzMMw\nHMmE6Z+fAgAqx0+AOuK2FomPiIiIiCgUtO8CBoA7qR/O/Ww+Ev/4G6RseAKY8+cW6eGIWPoHyMVF\nKF3wIspnPlF3PD17wd2zF5zf/4H3b9LVK1BOnIC7f3+/x0VEREREFEp4JDgA87MzsUdKwYjsbQjb\nuMHvry+f+xbha/8H7m7dUf7wT5v8fD22I9TbvgPdGun32IiIiIiIQkmjCpisrCyMGzcO77zzzg33\n3XnnnZg6dSqmT5+O6dOnIzc31+9BtjRDmIJFvdaiGJGwzpvrPd7EXywvL4LkdIprt5jNfn1tIiIi\nIqL2pMEhZA6HAwsXLsTIkSPrfEx6ejosFotfA2tt0YO64xdZb+Dt0ocROXsGirb81S+nKlYOf42w\nLZvgGjAQlffe74dIiYiIiIjarwZb6CaTCenp6bDb7a0RT8D07athHR7Ct0PugenzPQhf9Ue/vK51\n4fPi2i2/fYHXbiEiIiIi8lGDPTAGgwEGQ/0Pmz9/PnJycnDrrbdizpw5kOo5CD4mJgIGg9L0SH1k\ns9V//Iing2nT2DV4KicZ1sUvwHrrQCAuDtC0G6devYCuXet/03/8A9j9T2DcOHS4f5KfPgm1toZy\nh6guzB3yBfOHmou5Q74Ihfzx+Sxks2fPxpgxYxAdHY1Zs2Zhx44dGD9+fJ2PLyhw+PqWTWazRSIv\nr6Tex3TuLAGw4rPjMfjZkmWIfnAKcM89dT5eDwtD6aJXUPHgT2o/a5mmocOcp2AEUPDsfKgNvD8F\np8bkDlFtmDvkC+YPNRdzh3wRTPlTXyHlcwEzaVJVz0JKSgqysrLqLWCCVadOOqKjdRw7psA5Pg3F\n6etg+M9BMexLlqHLMiBLgKwAbhXh69Yg8qknYfz3Zyh9bRn0yKgarxe29X0YDx9Cxb33Q00eFKBP\nRURERETUtvhUwJSUlODJJ5/EypUrYTKZ8OWXX+Luu+/2V2ytSpKApCQ39u9XUF4OYOIPUTnxh3U+\nvuLBhxH12MMwb9sK46H/oDh9HdRBQ8SdlZWwvLwIusmEsmd/2zofgIiIiIioHWjwqPLMzExMnz4d\nH3zwAf785z9j+vTpePvtt/GPf/wDkZGRSElJweTJkzFlyhTExsaGZO+LR1KSBk2TcOJEwwfba126\novDD7Sh78teQvz2LDmnjEJ6+EtB1hL+dDuXctyj/yU+hde/RCpETEREREbUPkq7remu+YSDG1TV2\nPN+6dUbMnWvGsmXlmDJFbfTrG3ftRNSsn0HOz0Pl+DQYv8gA3Bqu7v9f6LEdfQmdAiyYxoJSaGHu\nkC+YP9RczB3yRTDlT33HwPC8vtX07asBAI4da9pZ0lx3jEXBrs/hHJ2CsE+2Qy4ogGP2L1m8EBER\nERH5mc8H8bclSUluAMCxY02v67T4BBS9vw3hK96A4chhlP90hr/DIyIiIiJq91jAVBMdDXTpojWr\ngAEAKArKZ//Kv0EREREREZEXh5BdJylJQ26ujKtXAx0JERERERFdjwXMdaqGkTXtOBgiIiIiImp5\nLGCuk5QkDuQ/fpyrhoiIiIgo2LCVfh1PAXP0KFcNEREREVGwYSv9OrfcokFRdA4hIyIiIiIKQixg\nrhMWJoqY48dltO4lPomIiIiIqCEsYGqRlKShtFTC+fNSoEMhIiIiIqJqWMDUwnMcTLOvB0NERERE\nRC2CLfRa8FTKRERERETBiQVMLdgDQ0REREQUnNhCr0W3bjo6dtSwZ48CVQ10NERERERE5MECphay\nDEycqCI/X8Znn3EYGRERERFRsGABU4d773UBADZvNgY4EiIiIiIi8mABU4dhwzT06KFh+3YDysoC\nHQ0REREREQEsYOokSaIXxuGQ8MknhkCHQ0REREREYAFTr3vvFUfwb9nCYWRERERERMGABUw9evXS\nMGiQG7t2KcjPlwIdDhERERFRu8cCpgH33uuC2y1h2zYOIyMiIiIiCjQWMA34wQ9UyLLOs5ERERER\nEQUBFjANiI/XMWaMG199peDMGQ4jIyIiIiIKJBYwjeC5JgwP5iciIiIiCqxGFTBZWVkYN24c3nnn\nnRvu27t3L/77v/8bkydPxooVK/weYDCYMEFFeLiOLVuM0PVAR0NERERE1H41WMA4HA4sXLgQI0eO\nrPX+RYsWYfny5Xj33Xfx+eef4+TJk34PMtAiI4G771Zx6pSMQ4fYaUVEREREFCgNtsZNJhPS09Nh\nt9tvuO/8+fOIjo5Gp06dIMsyvve97yEjI6NFAg00zzAyHsxPRERERBQ4DRYwBoMBZrO51vvy8vIQ\nGxvrvR0bG4u8vDz/RRdE7rjDjdhYDR98YICqBjoaIiIiIqL2qdUvbhITEwGDQWntt4XNFunza0ye\nDKxcCRw+HIm77vJDUBQS/JE71D4xd8gXzB9qLuYO+SIU8senAsZutyM/P997Ozc3t9ahZtUVFDh8\nectmsdkikZdX4vPrpKUpWLkyAqtXuzBkSIUfIqNg56/cofaHuUO+YP5QczF3yBfBlD/1FVI+HZHe\ntWtXlJaWIjs7G6qqYteuXRg1apQvLxnURoxwo3t3Ddu3G+Bo/TqMiIiIiKjda7AHJjMzE6+88gpy\ncnJgMBiwY8cO3HnnnejatStSU1OxYMECzJkzBwCQlpaGxMTEFg86UCRJHMz/+uth2LHDgB/8gAfD\nEBERERG1JknXW/fKJoHolvJnd1hWlozRoy1ITVXxl7+U++U1KXgFU1cqhRbmDvmC+UPNxdwhXwRT\n/rTYELL2qHdvDYMGubFzp4KzZ6VAh0NERERE1K6wgGmGxx93QtMkvPWWKdChEBERERG1KyxgmmHi\nRBXduml4910j8vPZC0NERERE1FpYwDSDwQDMmOFEebmENWuMgQ6HiIiIiKjdYAHTTA884EJsrIa1\na00oKwt0NERERERE7QMLmGayWICHH3ahoEDChg3shSEiIiIiag0sYHzwyCMuhIfrWLnSBJcr0NEQ\nEREREbV9LGB80LGjjqlTXcjOlrFtW4PXBCUiIiIiIh+xgPHRjBlOKIqON980oXUvCUpERERE1P6w\ngPFR9+46Jk5UcfSogl27lECHQ0RERETUprGA8YNZs5wAgOXLeWFLIiIiIqKWxALGD5KTNdx+u4rP\nPzfg4EGuUiIiIiKilsLWtp888YTohXnzTfbCEBERERG1FBYwfjJ6tBuDBrnx8ccGnD4tBTocIiIi\nIqI2iQWMn0iS6IXRdQkrVrAXhoiIiIioJbCA8aMJE1TcdJOGTZuMyMlhLwwRERERkb+xgPEjRQF+\n9atKVFZKWLgwLNDhEBERERG1OSxg/Oz++1UMGeLG1q1GfPEFrwtDRERERORPLGD8TJaBRYsqAADP\nPRcGTQtwQEREREREbQgLmBYwfLiGH/7QhUOHFGzcaAh0OEREREREbQYLmBby299WIjxcx6JFYSgp\nCXQ0RERERERtAwuYFtKli44nnnAiL0/G0qU8rTIRERERkT+wgGlBM2c60aWLhlWrTDhzhqdVJiIi\nIiLyFQuYFhQRAcyfXwmnU8KCBTytMhERERGRrxp1hPnixYtx6NAhSJKEefPmYeDAgd777rzzTiQk\nJEBRxCmDlyxZgvj4+JaJNgRNnKhizRoVf/ubEZ995kJKijvQIRERERERhawGC5j9+/fj22+/xcaN\nG3Hq1CnMmzcPGzdurPGY9PR0WCyWFgsylEkSsGhRJe66S8FvfxuGnTsdMPDEZEREREREzdLgELKM\njAyMGzcOANCzZ08UFRWhtLS0xQNrSwYN0vDAAy4cO6Zg/XpjoMMhIiIiIgpZDRYw+fn5iImJ8d6O\njY1FXl5ejcfMnz8fDzzwAJYsWQJd1/0fZRvw7LNOWK06XnnFhPx8HtBPRERERNQcTR7MdH2BMnv2\nbIwZMwbR0dGYNWsWduzYgfHjx9f5/JiYCBgMStMj9ZHNFtnq71nz/YEFC4Bf/1rCj35kxT//CXTo\nENCQqJECnTsUupg75AvmDzUXc4d8EQr502ABY7fbkZ+f7719+fJl2Gw27+1JkyZ5l1NSUpCVlVVv\nAVNQ4GhurM1ms0UiLy/wV5OcPh04dCgM69ebkJrqxqZNDlitgY6K6hMsuUOhh7lDvmD+UHMxd8gX\nwZQ/9RVSDQ4hGzVqFHbs2AEAOHLkCOx2O6zXWt0lJSV45JFH4HQ6AQBffvklevXq5Y+Y2yRJAl59\ntRL33uvCgQMKHnwwHOXlgY6KiIiIiCh0NNgDM3ToUPTv3x9TpkyBJEmYP38+tm7disjISKSmpiIl\nJQWTJ09GWFgY+vXrV2/vCwGKAixfXoGKCuDjj414+OFwrFtXjjBeJoaIiIiIqEGS3spH3QeiWyqY\nusM8nE7gxz8Ox86dBkyY4EJ6egVPrxyEgjF3KDQwd8gXzB9qLuYO+SKY8senIWTUMkwmYO3acowa\npeLjj4144gkz3LzGJRERERFRvVjABFB4OLB+fTluvdWNLVuMmDs3DDwLNRERERFR3VjABJjVCrz3\nngPJyW6sX2/C44+bUVYW6KiIiIiIiIITC5ggEB0NbNpUjmHD3PjgAyPS0iJw+jQvdklEREREdD0W\nMEGiY0cdH37owMMPO3HsmILUVAt27Gj9C34SEREREQUzFjBBxGQCXn65EsuXl8PlAqZPj8DLL5t4\ncD8RERER0TUsYILQ5MkqPv7Yge7dNbz2WhimTg1HQUGgoyIiIiIiCjwWMEEqOVnDp5+WYdw4Fbt2\nGZCaasGBA/y6iIiIiKh9Y4s4iHXoALzzTjmeeqoS589LSEuz4Mknw5CfzwP8iYiIiKh9YgET5GQZ\neOopJ7ZtK0e/fm5s2GDCyJEWrFljhKoGOjoiIiIiotbFAiZEfOc7bnz6qQMvvVQBXQeefdaMceMi\nsG8fz1RGRERERO0HC5gQYjAAjzziQkZGGaZOdeLoUQXf/34EZsww4+JFDisjIiIioraPBUwIstl0\nLF1aib/9rQyDBrmxZYsRw4ZZMGuWGYcP8yslIiIioraLrd0QduutGj75xIGlS8tx000a3n/fiLFj\nLZg4MRzbtxt4/RgiIiIianNYwIQ4RQGmTlWxZ48D777rwO23q8jIMOChh8IxcqQF6elGXLkiQdMC\nHSkRERERke8MgQ6A/EOWgbFj3Rg7thzHj8v4n/8x4v33jfjNb8z4zW8AWdYRHQ106KCjQwcd0dE6\nYmJ0dO+u4dFHXYiP1wP9EYiIiIiIGsQCpg3q21fDa69VYt48J9avN+KrrxQUFgKFhRIKCyVcuCCj\nsrLqoP/0dBNmznRi5kwnrNYABk5ERERE1AAWMG1YXJyOX/7SecPfdR0oLweKiiTs2GHA739vwpIl\nYVi3zoinnnJi2jQXjMYABExERERE1AAeA9MOSRIQEQF06qTjoYdc+OKLMjz1VCUcDglPP21GSooF\nH39sgN6MUWUFBcDevQpOnZKa9XwiIiIiovqwB4ZgtQJPPeXEgw+68Ic/mLB+vRE/+Uk4hgxxY+hQ\nNzp10tG5s4bOnXV06qShUycdZjOQmyshM1PG118r+PprGYcPKzh3rqom7tRJw6hRbowZo2L0aDe6\ndWNFQ0RERES+kXS9dfeT5+WVtObbAQBstsiAvG+oOnlSwqJFYdi+ve5xZBaLjrKymhfPjIvTMHCg\nhn793MjOlvHvfyvIz68qaLp31zBmjIrvfteNkSPd6No1+Asa5g41F3OHfMH8oeZi7pAvgil/bLbI\nOu9jDwzd4JZbdKxbV4GrVyuQkyPj4kVx4P/FixIuXpRx4YKEvDwJPXpoSE7WMHCgGwMHakhI0CFV\nq2l0HfjmG1HI7NmjYO9eA/7yFxP+8hdxf9euGm67TRQz3/mOG716aZAk8bzLlyWcPi3j1CkxnT4t\nTkDQp4+GAQM0DBjgRt++GiIibozf4QCOH5dx5IiCzEwZJ0/KiIvT0bu35p0SEzWYTK2zPomIiEKV\n2w28/bYRERE6pkxRIfPgAwoC7IGhVuN2A0eOyNi7V8G+fWK6erVqS9ixoxieduaMfEPvTm1kWUfP\nnqKguekmDWfOyDhyRBQ8mlb/8w0GHTffLIqZESPcSEtT0b37jf8KrZE7JSXA/v0K9u5VcPCggoQE\nHcOHuzF8uBtJSRoM3M0QkrjdIV8wf6i5/Jk7V65ImDHDjN27xQ/RiBEqXn+9Er168eJybVUwbXvq\n64FhAUMBo+tAVpaMffsUZGQo+OILBVeuSEhM1NCzp4abb/bMRbERFaUjK0tGZqaMzEzFOy8pqSpW\nIiN19O/vRv/+orDp39+N3r01XLkiIStLxjffyDhxQsY33yjIypJRXFz13AEDRCGTlqYiKUn0BtWV\nO6oKVFQAFgtq9Do1RmEh8MUXokcqI0McP1RXwWWx6Bg61O0taCIigEuXJOTmSsjNlXHpkoTLl8Vt\nRQFuuqlqfSUminWYkKAH/R4zTRNF3NatBpw6JWPwYDdGjBCfOTY20NE1D7c75AvmDzWXv3Lnq69k\nPPpoOHJyZKSmqjCbdfz1r0aYTDrmzHHi5z938oylbVAwbXt8LmAWL16MQ4cOQZIkzJs3DwMHDvTe\nt3fvXrz22mtQFAUpKSmYNWtWva/FAobqo+tNKwh0HTh3TsLZszISEzV066Y3+vm6Dly4IGHnTgO2\nbzdgzx4FLpd48k03aUhLUzFokAknT1ZeKxpEwXDpkhhCp+sSDAbPhUFrXiTUYtFRUiKhqEhCcbGE\noiJ4l6tfg8do1DFkiNt7XNDw4W5cuiThyy8V7/TNN0qDnyUmRofLBZSW3vjhw8N1JCToMBhEIXP9\nZDQCdrvo/erUSUdCgmdZFD/h4YDScAg1aJr4Huv7LnQd+PprGVu3GrFtmwEXLtReZfXuLYqZESPc\nGDpUQ1ycBqsVjRoCqOtAZSVQViZB0wBF0aEoVZ9dUcRkMDS9EG1IS2x3iovFd2yx6LBYwN65NixU\nfrcuXJBQUQF07apzWG6Q8DV3dB1Yu9aI558Pg9sNPPOME7NnOyHLwMcfG/DMM2HIzZXRr58bS5dW\nYPBg9sa0JcG07fGpgNm/fz/WrFmDVatW4dSpU5g3bx42btzovT8tLQ1r1qxBfHw8pk2bht/97ne4\n5ZZb6nw9FjAUrIqLgU8/FcXMp58a4HDUXgzEx4tGvsUiihLPRUKLiiRvAVSd0SiKmuhoIDpaFDmD\nB4uiZdgwd63H8VRXUAAcPCiKGV0H7HYRQ3y8hvh4HXa7OCucrgP5+eLYoTNnJJw5I+P0aTHl5ooG\nvJiqL4sGvttdf+tdlkXjxGgEwsJ0GI1iWdMAl8szSd5lt1tCeLh+LVbtWrxVcZ89K+PDD404fVoU\nLVFROiZMUDFpkgtDhrhx6JDokdu/X8GBA0qt34XZrMNq1REZKXreLBYdlZUSSktFwVJaKqGsDFDV\nhiuTyEgdt9xS1et3yy1VvYAWS4NPr8HpFI06l8uK/HyHdz273WKu62KyWMTnFrkhChJPT5mqAqdP\nyzh61DMpOHpURnZ2zSIvLEz3FjMWiw6rVRSznik2tmoeFSWKN09hKUmo0TPncIjiqLQUKCmRri1L\ncDjEaddjYkTueuaeSVFEDlVWSnA6xbLTKaGyUhRYMTG6N+8jI/1fKNanslIch5eZKY6J0zSgSxcN\nXbvq6NJFQ5cuIiebWqA3l9Mp4jl8WHyngNgmXL9OO3TQ0auXFW53SYv2nuo6kJcn4cQJGWfPyoiK\nqjrjpN1+43qpqBA7HQ4cEP+XX32l4OJFEaAs6+jSRUePHtq1SSx36yZ2iNjteqvsrS8vF3GqqgRV\nFbdg5k0AAA6KSURBVP9Lnm2SqorthudMmm2VL22e0lJgzhwzPvjAiLg4DW+9VYGUFHeNxxQVAS+8\nEIZ33jFBlnU89pgLTz9d2eBvGSC2gSUl4rezqEiCwyEhIUHkHHtzGqeiQvw+XLwoNqbX75CTJDFM\nPiqqqs0RFtb41w+mNrNPBcwbb7yBzp0747777gMAjB8/Hps3b4bVasX58+cxd+5cvPvuuwCAVatW\nISIiAtOnT6/z9VjAUCioqAD27FGgqhGIiHAgIUEULVFRdTfAdB0oK4N3oxwVJRqNZnPrNtqaStPE\nOOdLlyTviRouXpSuDU+TUVEhGl4ul3RtLhqoLldVD47RWFXUeJZLS6t6q2obIhceruPuu1VMmqRi\n7Fi1zg2sqgJHj8rYv1/B4cMKiourGtglJUBxsYSSErHOPQ16qxXehr3VqiMiQjTGPEWEpklwu+Gd\n8vJE4ed03hhnXJx2rYFZsxEfEyM+56VLEnJyxIkucnIk5OU1r8Upy+IHJzJSx+XLNXvqANFL1q+f\nhthYHQ6HKNLKyqRqy2JdNKZgCxRFqSrmIyOresM8PWOe2waDZ9K9y0Zj1e3wcCAiQny/Yq4jIkIU\ndGfPiqGlhw/LyMqSG1wfBoNo0NpsOsLDxevUNg8LE69vMsG7HBYGmEw1e/WqNyZUVQyTPXxYnG7+\nm2/kWndy1EWWRZ517CiK0I4dxRQVVbVDwWgUMYi5+P/zrMPq61NRdKiqhNOnJZw4oeDECTGctqio\n9ngMBtFz27mz6InNzhafo3r8NpuGYcPcsFpFT/i338q4dKn2/JckHXFx4jU7dRI7MmJjxU6H8nKg\nvLzmvLJSgtEo1rHZ7FnXYtlkEjlfWAgUFIiGsGdeUdG49RsTI7bpIh4xj43VoeuosbPHcxsQ37nZ\nLPLBbBaxiLn4rmT5xh0Etd2umuu1/K1qasrvRvX3iYuz4sqVUkiSXuM+z7JnJwrgWRaf8+JFcbxL\nVpaC4cPdWL26HJ061d1E/Pe/FfzqV2acPSvDYKj5PyL+T6oazmIkgoTiYvF+15NlHZ076+jWTexg\n6NZNjKgID6++najZi67rVTvPPIWqmEuQZfF/ERZWtePNE5fJpNdYxzX/f/U6vzNNEzsrr1yRcPVq\nzXlhoQSTSWzXoqLEzhpPGyAyUsRR1/bO81lqfidiKi6WcPKkOLbXMz9/Xqp1HdbHbK7akRQdLXI9\nLq5qm+KZ4uJ0pKRYUFgYHG1mn85Clp+fj/79+3tvx8bGIi8vD1arFXl5eYitNkA9NjYW58+f9zFc\nosAzm4HUVDdsNiAvz93wEyA2claraDADwX+KaA9ZBmw20YBLTgaAxn3exnK7Rc+Q51id3FwZVquO\nsWNVWK0NP99gAAYOFKfoBlx1Pq6pww9rizM7W/Ke+c4z5eSIxtHp01K9PVVhYaJh1ru3ik6ddNx8\nsxGqWnlDo9YTo8NRtRfSM8zQ8yPfp48oVvr1c6NfPw1JSRpstoZzStfFHtSrV0XM1efFxVWNseo/\nlp7GmafY8xSAondLNODLy8UP99Wr4oe6oKBqrmnwNuQ9c08jX1VRo3Hp6a0sLBR54OmZEoWlfwuv\niAgdgwZpSE52e89caDQCOTkScnJEb5ZnOSdHwpEj8g1Foz+ZzTqSk0UcnrnRWLU+qibRKHc4TLhw\nwY2rVyXk54tekqY2WupjMOhITNQwapSGXr3EMXOlpWJ9XLhQNT9wQIGmieGyycmiYLn1VtF7XNuQ\n3fJy4Px52VvQnDsneoDFDhLRCDt8uOHPoSh6gz3DgCiMOnQQQ3i7dNEQHS0avVVFsPisnqGiZWWS\ndyhwdraMY8eCt+D3TSM2rnV47DEnnn++ssEekdGj3di9uwxLl5qwZ4/hWu9rVW9sWZkoKHVd9AR0\n7qyhb1/xfUVFeXoGdFy6JBrl58+LY2L9medtjd2uYeRIN3r21NC9u/j/q7kd9YyMEMWi2O5K3nlu\nroysrNqLSI/p04E//KEVP1QzNXkEta/H/MfERMBgaKX++mrqq+KI6sPc8V1CQqAjaJyEBGDYsNrv\n03Ux9OHqVeDKFTGvqAC6dAG6dgVsNgmSJAGovge6Cf32N1AANH1Mhd0O3HyzD28bIJ7iyu1GjaE/\n18+dTlzrdao5lZaKv3fvDgwZAvTqJUFRFIj12Dhud9VrV587HGI4WkWFZ7hczeXqQwSrLwNAr14i\nnr59pWu/fU35/av6iXa7Rc7l54shPJ51Udvkacyoas1lWRa5kZQE9OwpwWhsOB5VBXJzgdhYCeHh\njYu/e3dg1Kja79N1Ef+FC+LzmM1iiGL1SRx3J4pjp7NqXVdUVC1brUBsLBAVJV0bZte8Rm9pKZCT\nUxVPbT1pnj3kFRW41kskJoejasiaZ8dA9R0E19/25Eddy7X9raHjCD3z2vbg17VcvYcBqFpWFOCB\nB4BJk0wAGn9A0+uvN+ZRjft+nE4gOxs4exY4d06s2+q95dWnqhEAnh5a1Bje7BnSev3kctXc3lRf\n9273jd+dZw6InIuLE5PNVrUcGyveTxzvims7pKqWxVDt2qfqx4xeP1mtQO/eQJ8+YlsSHS2j5m9M\n02maGJqelyem/PyayxMnhka7p8ECxm63Iz8/33v78uXLsNlstd6Xm5sLu91e7+sVFDiaG2uzcQgZ\nNRdzh64njjcRjbTqqm0KATB3/EWWPUO2mva8q1eb/56KgmvHVjX/Na5XUNC0x9eVP54Gk68KCxv/\nWJNJNPRLS31/Xw+bTUzX8xQH15PlqgLHw+USOxN8FRuLkD3bYW183fbk5fkxmGaIjASSk3FtREDo\nMBhEfnbq1DKv73T697vp2FFM1wum3676CqkGy7hRo0Zhx44dAIAjR47AbrfDem3cR9euXVFaWors\n7Gyoqopdu3ZhVF27XYiIiIiIiHzUYA/M0KFD0b9/f0yZMgWSJGH+/PnYunUrIiMjkZqaigULFmDO\nnDkAxBnJEhMTWzxoIiIiIiJqn3ghS6J6MHeouZg75AvmDzUXc4d8EUz549MQMiIiIiIiomDBAoaI\niIiIiEIGCxgiIiIiIgoZLGCIiIiIiChktPpB/ERERERERM3FHhgiIiIiIgoZLGCIiIiIiChksIAh\nIiIiIqKQwQKGiIiIiIhCBgsYIiIiIiIKGSxgiIiIiIgoZBgCHUBLWrx4MQ4dOgRJkjBv3jwMHDgw\n0CFRkHv11Vfx1VdfQVVVPPbYY0hOTsbcuXPhdrths9nw+9//HiaTKdBhUpCqqKjAPffcg5kzZ2Lk\nyJHMHWq0jz76CKtXr4bBYMDs2bPRp08f5g81qKysDE8//TSKiorgcrkwa9Ys2Gw2LFiwAADQp08f\nvPDCC4ENkoJOVlYWZs6ciYceegjTpk3DxYsXa93efPTRR/jTn/4EWZZx//3347777gt06F5ttgdm\n//79+Pbbb7Fx40a8+OKLePHFFwMdEgW5ffv24cSJE9i4cSNWr16NxYsXY9myZZg6dSo2bNiAHj16\nYPPmzYEOk4LYypUrER0dDQDMHWq0goICrFixAhs2bMBbb72FnTt3Mn+oUT744AMkJiZi/fr1eOON\nN7ztnXnz5uG9995DaWkp/vWvfwU6TAoiDocDCxcuxMiRI71/q21743A4sGLFCqxbtw7r16/Hn/70\nJxQWFgYw8prabAGTkZGBcePGAQB69uyJoqIilJaWBjgqCmbDhw/HG2+8AQCIiopCeXk5vvjiC4wd\nOxYAcMcddyAjIyOQIVIQO3XqFE6ePInbb78dAJg71GgZGRkYOXIkrFYr7HY7Fi5cyPyhRomJifE2\nKouLi9GhQwfk5OR4R5wwd+h6JpMJ6enpsNvt3r/Vtr05dOgQkpOTERkZCbPZjKFDh+LgwYOBCvsG\nbbaAyc/PR0xMjPd2bGws8vLyAhgRBTtFURAREQEA2Lx5M1JSUlBeXu4dttGxY0fmENXplVdewTPP\nPOO9zdyhxsrOzkZFRQUef/xxTJ06FRkZGcwfapQJEybgwoULSE1NxbRp0zB37lxERUV572fu0PUM\nBgPMZnONv9W2vcnPz0dsbKz3McHWjm7Tx8BUp+t6oEOgEPHpp59i8+bNWLt2Le666y7v35lDVJcP\nP/wQgwcPRrdu3Wq9n7lDDSksLMSbb76JCxcu4MEHH6yRM8wfqsu2bdvQuXNnrFmzBsePH8esWbMQ\nGRnpvZ+5Q01VV84EWy612QLGbrcjPz/fe/vy5cuw2WwBjIhCwZ49e/DWW29h9erViIyMREREBCoq\nKmA2m5Gbm1ujy5XIY/fu3Th//jx2796NS5cuwWQyMXeo0Tp27IghQ4bAYDCge/fusFgsUBSF+UMN\nOnjwIEaPHg0A6Nu3LyorK6Gqqvd+5g41Rm2/V7W1owcPHhzAKGtqs0PIRo0ahR07dgAAjhw5Arvd\nDqvVGuCoKJiVlJTg1VdfxapVq9ChQwcAwHe/+11vHv3973/HmDFjAhkiBamlS5diy5Yt2LRpE+67\n7z7MnDmTuUONNnr0aOzbtw+apqGgoAAOh4P5Q43So0cPHDp0CACQk5MDi8WCnj174sCBAwCYO9Q4\ntW1vBg0ahMOHD6O4uBhlZWU4ePAghg0bFuBIq0h6sPUJ+dGSJUtw4MABSJKE+fPno2/fvoEOiYLY\nxo0bsXz5ciQmJnr/9vLLL+O5555DZWUlOnfujJdeeglGozGAUVKwW758Obp06YLRo0fj6aefZu5Q\no7z33nveM43NmDEDycnJzB9qUFlZGebNm4crV65AVVX84he/gM1mw/PPPw9N0zBo0CA8++yzgQ6T\ngkhmZiZeeeUV5OTkwGAwID4+HkuWLMEzzzxzw/bmk08+wZo1ayBJEqZNm4bvf//7gQ7fq00XMERE\nRERE1La02SFkRERERETU9rCAISIiIiKikMEChoiIiIiIQgYLGCIiIiIiChksYIiIiIiIKGSwgCEi\nIiIiopDBAoaIiIiIiEIGCxgiIiIiIgoZ/we5swqpbO1KIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f170275dcf8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "rCt7TCIa0xbI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save_weights(\"resnet50_cifar10_weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_pFqZ_0OpwJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}